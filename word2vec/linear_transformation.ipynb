{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import codecs\n",
    "import io\n",
    "import logging\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Log output. Also useful to show program is doing things\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-24 09:53:45,782 : INFO : loading Word2Vec object from model_CBOW_jp_wzh_2.w2v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-24 09:53:46,190 : INFO : loading wv recursively from model_CBOW_jp_wzh_2.w2v.wv.* with mmap=None\n",
      "2018-05-24 09:53:46,192 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-05-24 09:53:46,193 : INFO : setting ignored attribute cum_table to None\n",
      "2018-05-24 09:53:46,194 : INFO : loaded model_CBOW_jp_wzh_2.w2v\n",
      "2018-05-24 09:53:46,268 : INFO : loading Word2Vec object from model_CBOW_en_wzh_2.w2v\n",
      "2018-05-24 09:53:46,567 : INFO : loading wv recursively from model_CBOW_en_wzh_2.w2v.wv.* with mmap=None\n",
      "2018-05-24 09:53:46,568 : INFO : loading syn0 from model_CBOW_en_wzh_2.w2v.wv.syn0.npy with mmap=None\n",
      "2018-05-24 09:53:46,591 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-05-24 09:53:46,592 : INFO : loading syn1neg from model_CBOW_en_wzh_2.w2v.syn1neg.npy with mmap=None\n",
      "2018-05-24 09:53:46,614 : INFO : setting ignored attribute cum_table to None\n",
      "2018-05-24 09:53:46,615 : INFO : loaded model_CBOW_en_wzh_2.w2v\n"
     ]
    }
   ],
   "source": [
    "# models trained using gensim implementation of word2vec\n",
    "print('Loading models...')\n",
    "model_source = gensim.models.Word2Vec.load('model_CBOW_jp_wzh_2.w2v')\n",
    "model_target = gensim.models.Word2Vec.load('model_CBOW_en_wzh_2.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "targets = []\n",
    "with open(\"./ja-en.txt\",'r',encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        source,target = line.split()\n",
    "        sources.append(source)\n",
    "        targets.append(target)\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['から',\n",
       " 'として',\n",
       " '日本',\n",
       " '日本',\n",
       " 'この',\n",
       " 'まで',\n",
       " 'まで',\n",
       " 'また',\n",
       " '昭和',\n",
       " 'もの',\n",
       " '大学',\n",
       " '大学',\n",
       " '大学',\n",
       " '大学',\n",
       " 'テレビ',\n",
       " 'テレビ',\n",
       " 'テレビ',\n",
       " '放送',\n",
       " '放送',\n",
       " '東京',\n",
       " 'より',\n",
       " '削除',\n",
       " '削除',\n",
       " '削除',\n",
       " '削除',\n",
       " '削除',\n",
       " '現在',\n",
       " '現在',\n",
       " '現在',\n",
       " '平成',\n",
       " '学校',\n",
       " '学校',\n",
       " 'これ',\n",
       " '世界',\n",
       " 'アメリカ',\n",
       " 'でも',\n",
       " 'について',\n",
       " '作品',\n",
       " '作品',\n",
       " '時代',\n",
       " '映画',\n",
       " '映画',\n",
       " '映画',\n",
       " '映画',\n",
       " '監督',\n",
       " '監督',\n",
       " '鉄道',\n",
       " '鉄道',\n",
       " '鉄道',\n",
       " '鉄道',\n",
       " '使用',\n",
       " '出演',\n",
       " '出演',\n",
       " '出演',\n",
       " '明治',\n",
       " '時間',\n",
       " '時間',\n",
       " '時間',\n",
       " '開始',\n",
       " '開始',\n",
       " '開始',\n",
       " 'シリーズ',\n",
       " 'のみ',\n",
       " '記事',\n",
       " '記事',\n",
       " '記事',\n",
       " '記事',\n",
       " '活動',\n",
       " '選手',\n",
       " '選手',\n",
       " 'しかし',\n",
       " '研究',\n",
       " '研究',\n",
       " '会話',\n",
       " '会話',\n",
       " '大阪',\n",
       " '大会',\n",
       " 'チーム',\n",
       " 'チーム',\n",
       " '存在',\n",
       " '優勝',\n",
       " '作詞',\n",
       " '所属',\n",
       " '所属',\n",
       " '国際',\n",
       " '一部',\n",
       " '一部',\n",
       " '結果',\n",
       " '結果',\n",
       " 'アルバム',\n",
       " 'アルバム',\n",
       " 'バス',\n",
       " 'バス',\n",
       " 'バス',\n",
       " 'ゲーム',\n",
       " 'ゲーム',\n",
       " 'ゲーム',\n",
       " '問題',\n",
       " '問題',\n",
       " '問題',\n",
       " '問題',\n",
       " 'リーグ',\n",
       " 'リーグ',\n",
       " '利用',\n",
       " '開発',\n",
       " '事業',\n",
       " '決定',\n",
       " '決定',\n",
       " '音楽',\n",
       " '転送',\n",
       " '転送',\n",
       " '転送',\n",
       " '転送',\n",
       " '情報',\n",
       " '情報',\n",
       " '公式',\n",
       " '公式',\n",
       " '参加',\n",
       " '参加',\n",
       " '地域',\n",
       " '地域',\n",
       " '変更',\n",
       " '変更',\n",
       " '変更',\n",
       " '編曲',\n",
       " '編曲',\n",
       " '編曲',\n",
       " 'サイト',\n",
       " 'サイト',\n",
       " '丁目',\n",
       " '記録',\n",
       " '記録',\n",
       " '関係',\n",
       " '関係',\n",
       " 'クラブ',\n",
       " 'クラブ',\n",
       " '中央',\n",
       " '中央',\n",
       " '中央',\n",
       " '中央',\n",
       " '同じ',\n",
       " '設立',\n",
       " '設立',\n",
       " '設立',\n",
       " '考え',\n",
       " '考え',\n",
       " '教育',\n",
       " 'プロ',\n",
       " '設置',\n",
       " '発表',\n",
       " '発表',\n",
       " '小学校',\n",
       " '編集',\n",
       " '編集',\n",
       " '編集',\n",
       " '編集',\n",
       " 'シーズン',\n",
       " 'シーズン',\n",
       " 'ファイル',\n",
       " 'ファイル',\n",
       " 'フランス',\n",
       " '都市',\n",
       " '都市',\n",
       " '出版',\n",
       " '出版',\n",
       " '出版',\n",
       " '会社',\n",
       " '会社',\n",
       " '会社',\n",
       " '世紀',\n",
       " '世紀',\n",
       " 'ノート',\n",
       " 'ノート',\n",
       " 'ノート',\n",
       " 'ノート',\n",
       " '京都',\n",
       " '社会',\n",
       " '社会',\n",
       " 'ドイツ',\n",
       " '開催',\n",
       " 'シングル',\n",
       " 'センター',\n",
       " 'センター',\n",
       " '終了',\n",
       " '終了',\n",
       " '終了',\n",
       " '終了',\n",
       " '終了',\n",
       " '中心',\n",
       " '中心',\n",
       " '内容',\n",
       " '内容',\n",
       " '文化',\n",
       " 'イギリス',\n",
       " 'イギリス',\n",
       " 'ドラマ',\n",
       " 'ドラマ',\n",
       " 'さらに',\n",
       " '中国',\n",
       " '撮影',\n",
       " '撮影',\n",
       " '撮影',\n",
       " '選手権',\n",
       " '選手権',\n",
       " '野球',\n",
       " '指定',\n",
       " '指定',\n",
       " '位置',\n",
       " '以下',\n",
       " 'マン',\n",
       " '卒業',\n",
       " '卒業',\n",
       " '卒業',\n",
       " '人物',\n",
       " '文庫',\n",
       " '公開',\n",
       " '公開',\n",
       " '北海道',\n",
       " '北海道',\n",
       " '最終',\n",
       " '最終',\n",
       " 'アニメ',\n",
       " '確認',\n",
       " '確認',\n",
       " '一般',\n",
       " '歴史',\n",
       " '選挙',\n",
       " '選挙',\n",
       " '計画',\n",
       " '計画',\n",
       " '計画',\n",
       " '計画',\n",
       " '経済',\n",
       " '経済',\n",
       " 'ページ',\n",
       " 'ページ',\n",
       " '教授',\n",
       " '記念',\n",
       " 'ラジオ',\n",
       " '劇場',\n",
       " '劇場',\n",
       " 'グループ',\n",
       " 'グループ',\n",
       " '英語',\n",
       " '女性',\n",
       " '女性',\n",
       " '女性',\n",
       " '地区',\n",
       " '獲得',\n",
       " '得点',\n",
       " 'コメント',\n",
       " 'コメント',\n",
       " 'コメント',\n",
       " 'コメント',\n",
       " '漫画',\n",
       " '漫画',\n",
       " '他の',\n",
       " '自身',\n",
       " '就任',\n",
       " '廃止',\n",
       " '廃止',\n",
       " '販売',\n",
       " '販売',\n",
       " '攻撃',\n",
       " '攻撃',\n",
       " 'サッカー',\n",
       " 'リー',\n",
       " '議員',\n",
       " '全国',\n",
       " 'デビュー',\n",
       " '協会',\n",
       " '路線',\n",
       " 'フジ',\n",
       " '自分',\n",
       " '戦争',\n",
       " '戦争',\n",
       " '製作',\n",
       " '部分',\n",
       " '高校',\n",
       " '番号',\n",
       " '当初',\n",
       " '最初',\n",
       " '受賞',\n",
       " '受賞',\n",
       " '期間',\n",
       " '期間',\n",
       " '広島',\n",
       " '場所',\n",
       " '場所',\n",
       " '場所',\n",
       " '技術',\n",
       " '海軍',\n",
       " 'リンク',\n",
       " 'リンク',\n",
       " '合併',\n",
       " '合併',\n",
       " 'または',\n",
       " '道路',\n",
       " '道路',\n",
       " '特定',\n",
       " '特定',\n",
       " '朝日',\n",
       " '意味',\n",
       " '意味',\n",
       " 'システム',\n",
       " 'システム',\n",
       " 'モデル',\n",
       " 'モデル',\n",
       " '対応',\n",
       " '列車',\n",
       " '列車',\n",
       " '建設',\n",
       " 'とき',\n",
       " '最後',\n",
       " '科学',\n",
       " '理由',\n",
       " '理由',\n",
       " 'そして',\n",
       " '一つ',\n",
       " '大正',\n",
       " '大正',\n",
       " '最高',\n",
       " 'ブロック',\n",
       " 'ブロック',\n",
       " '車両',\n",
       " '車両',\n",
       " '自動車',\n",
       " '自動車',\n",
       " '人口',\n",
       " '人口',\n",
       " '特に',\n",
       " '特に',\n",
       " '営業',\n",
       " '発生',\n",
       " '新聞',\n",
       " '新聞',\n",
       " '連続',\n",
       " '連続',\n",
       " '政府',\n",
       " '構成',\n",
       " '構成',\n",
       " '構成',\n",
       " '構成',\n",
       " '最大',\n",
       " '最大',\n",
       " 'キャラクター',\n",
       " 'キャラクター',\n",
       " '小説',\n",
       " '小説',\n",
       " 'それぞれ',\n",
       " '機関',\n",
       " '機関',\n",
       " '機関',\n",
       " '参照',\n",
       " '参照',\n",
       " '参照',\n",
       " 'メンバー',\n",
       " 'メンバー',\n",
       " '発行',\n",
       " '発行',\n",
       " '発行',\n",
       " '発行',\n",
       " '画像',\n",
       " '画像',\n",
       " '画像',\n",
       " '画像',\n",
       " '状態',\n",
       " '状態',\n",
       " '名称',\n",
       " '名称',\n",
       " '名称',\n",
       " 'ダム',\n",
       " 'ホーム',\n",
       " '運行',\n",
       " '投稿',\n",
       " '投稿',\n",
       " '投稿',\n",
       " '名前',\n",
       " '名前',\n",
       " '福岡',\n",
       " '施設',\n",
       " '施設',\n",
       " '施設',\n",
       " '調査',\n",
       " '調査',\n",
       " '調査',\n",
       " '製造',\n",
       " 'イタリア',\n",
       " 'ロシア',\n",
       " 'ロシア',\n",
       " '独立',\n",
       " '独立',\n",
       " '物語',\n",
       " '物語',\n",
       " '物語',\n",
       " '神社',\n",
       " '神社',\n",
       " '神社',\n",
       " '企画',\n",
       " 'サン',\n",
       " '名古屋',\n",
       " '通常',\n",
       " '通常',\n",
       " '企業',\n",
       " '航空',\n",
       " '航空',\n",
       " 'スーパー',\n",
       " '帝国',\n",
       " 'トン',\n",
       " 'トン',\n",
       " 'トン',\n",
       " 'トン',\n",
       " '影響',\n",
       " '影響',\n",
       " '勝利',\n",
       " '勝利',\n",
       " '勝利',\n",
       " '勝利',\n",
       " '勝利',\n",
       " 'デザイン',\n",
       " 'デザイン',\n",
       " 'デザイン',\n",
       " '全て',\n",
       " '本社',\n",
       " '人間',\n",
       " '千葉',\n",
       " 'アン',\n",
       " 'アン',\n",
       " 'アン',\n",
       " '交通',\n",
       " '交通',\n",
       " '交通',\n",
       " '組織',\n",
       " '組織',\n",
       " '構造',\n",
       " '構造',\n",
       " '戦い',\n",
       " '実施',\n",
       " 'ここ',\n",
       " '以前',\n",
       " '以前',\n",
       " 'サービス',\n",
       " 'サービス',\n",
       " '統合',\n",
       " '統合',\n",
       " '統合',\n",
       " '統合',\n",
       " '統合',\n",
       " 'テーマ',\n",
       " 'テーマ',\n",
       " '面積',\n",
       " 'エンジン',\n",
       " 'エンジン',\n",
       " '主演',\n",
       " 'ビル',\n",
       " '日本語',\n",
       " '契約',\n",
       " '契約',\n",
       " '設定',\n",
       " '設定',\n",
       " '設定',\n",
       " '設定',\n",
       " '設定',\n",
       " 'ライブ',\n",
       " '含む',\n",
       " '含む',\n",
       " '含む',\n",
       " '専門',\n",
       " '専門',\n",
       " '機能',\n",
       " '機能',\n",
       " '機能',\n",
       " '機能',\n",
       " '身長',\n",
       " '所在地',\n",
       " '所在地',\n",
       " '完成',\n",
       " '表記',\n",
       " '運転',\n",
       " '写真',\n",
       " '写真',\n",
       " '写真',\n",
       " '写真',\n",
       " '関連',\n",
       " '関連',\n",
       " '書店',\n",
       " '高い',\n",
       " '高い',\n",
       " '高い',\n",
       " '生産',\n",
       " '横浜',\n",
       " '上の',\n",
       " '宇宙',\n",
       " '管理',\n",
       " '管理',\n",
       " 'バー',\n",
       " 'バー',\n",
       " 'ジョン',\n",
       " '部隊',\n",
       " '公園',\n",
       " '公園',\n",
       " 'スポーツ',\n",
       " 'スポーツ',\n",
       " '脚本',\n",
       " '脚本',\n",
       " '目的',\n",
       " '目的',\n",
       " '目的',\n",
       " '目的',\n",
       " '生活',\n",
       " 'カード',\n",
       " 'カード',\n",
       " '基本',\n",
       " '基本',\n",
       " '基本',\n",
       " '新潟',\n",
       " '女優',\n",
       " '女優',\n",
       " '不明',\n",
       " 'タイトル',\n",
       " 'タイトル',\n",
       " '政治',\n",
       " '電気',\n",
       " '電気',\n",
       " '警察',\n",
       " '作成',\n",
       " '作成',\n",
       " '作成',\n",
       " 'ガン',\n",
       " '予定',\n",
       " '予定',\n",
       " 'スター',\n",
       " '経営',\n",
       " '自由',\n",
       " '自由',\n",
       " '自由',\n",
       " '自由',\n",
       " '過去',\n",
       " '陸軍',\n",
       " '運営',\n",
       " '愛知',\n",
       " '表示',\n",
       " '社長',\n",
       " '社長',\n",
       " '団体',\n",
       " '団体',\n",
       " '工業',\n",
       " '通り',\n",
       " '外部',\n",
       " '通信',\n",
       " '通信',\n",
       " '通信',\n",
       " 'アル',\n",
       " '俳優',\n",
       " '俳優',\n",
       " '俳優',\n",
       " 'スペシャル',\n",
       " '少年',\n",
       " '病院',\n",
       " '病院',\n",
       " '結婚',\n",
       " '結婚',\n",
       " '個人',\n",
       " '個人',\n",
       " '個人',\n",
       " '区間',\n",
       " '銀行',\n",
       " '銀行',\n",
       " '研究所',\n",
       " '主に',\n",
       " '主に',\n",
       " '学園',\n",
       " '彼女',\n",
       " 'ニュース',\n",
       " 'その他',\n",
       " 'その他',\n",
       " 'ソフト',\n",
       " '文学',\n",
       " '能力',\n",
       " 'なし',\n",
       " 'なし',\n",
       " '江戸',\n",
       " '学者',\n",
       " '学者',\n",
       " '国内',\n",
       " '空港',\n",
       " '空港',\n",
       " 'ヨーク',\n",
       " '高速',\n",
       " '言語',\n",
       " '言語',\n",
       " '設計',\n",
       " '韓国',\n",
       " 'リリース',\n",
       " 'リリース',\n",
       " 'ベスト',\n",
       " 'ベスト',\n",
       " '現代',\n",
       " '会議',\n",
       " '会議',\n",
       " '会議',\n",
       " 'バンド',\n",
       " 'バンド',\n",
       " '追加',\n",
       " '追加',\n",
       " '追加',\n",
       " '成功',\n",
       " '成功',\n",
       " '移動',\n",
       " '移動',\n",
       " 'オリンピック',\n",
       " '国民',\n",
       " '国民',\n",
       " 'ファン',\n",
       " 'ファン',\n",
       " 'すべて',\n",
       " 'すべて',\n",
       " '山口',\n",
       " '運動',\n",
       " '運動',\n",
       " '環境',\n",
       " '環境',\n",
       " '発足',\n",
       " '大きな',\n",
       " '競技',\n",
       " '会長',\n",
       " '会長',\n",
       " 'ヨーロッパ',\n",
       " '紹介',\n",
       " '紹介',\n",
       " '形式',\n",
       " '工場',\n",
       " '工場',\n",
       " '相手',\n",
       " '戦闘',\n",
       " '戦闘',\n",
       " '労働',\n",
       " '労働',\n",
       " '事務所',\n",
       " '限定',\n",
       " 'データ',\n",
       " '作戦',\n",
       " 'オリジナル',\n",
       " 'オリジナル',\n",
       " 'オリジナル',\n",
       " '可能性',\n",
       " '可能性',\n",
       " '可能性',\n",
       " '演出',\n",
       " '種類',\n",
       " '種類',\n",
       " '種類',\n",
       " '文字',\n",
       " '文字',\n",
       " '大統領',\n",
       " '協力',\n",
       " '指導',\n",
       " '判断',\n",
       " '判断',\n",
       " '連邦',\n",
       " 'ネット',\n",
       " 'ネット',\n",
       " '共和国',\n",
       " '引退',\n",
       " '引退',\n",
       " '引退',\n",
       " '部門',\n",
       " '産業',\n",
       " '決勝',\n",
       " 'プロデューサー',\n",
       " 'プロデューサー',\n",
       " '系統',\n",
       " '誕生',\n",
       " '誕生',\n",
       " '指揮',\n",
       " '指揮',\n",
       " 'レース',\n",
       " 'レース',\n",
       " 'レース',\n",
       " '静岡',\n",
       " '郵便',\n",
       " '神奈川',\n",
       " '岡山',\n",
       " '埼玉',\n",
       " '項目',\n",
       " 'カップ',\n",
       " 'カップ',\n",
       " 'ラン',\n",
       " 'レイ',\n",
       " '移転',\n",
       " '移転',\n",
       " 'ほぼ',\n",
       " 'ほぼ',\n",
       " '交差点',\n",
       " 'イベント',\n",
       " 'イベント',\n",
       " '競馬',\n",
       " '異なる',\n",
       " '異なる',\n",
       " '神戸',\n",
       " 'カー',\n",
       " '出典',\n",
       " '出典',\n",
       " '関西',\n",
       " 'ほとんど',\n",
       " '行動',\n",
       " '行動',\n",
       " '行動',\n",
       " '行動',\n",
       " '重要',\n",
       " 'プロジェクト',\n",
       " 'プロジェクト',\n",
       " '九州',\n",
       " '九州',\n",
       " '電車',\n",
       " '電車',\n",
       " '建築',\n",
       " 'クラス',\n",
       " 'クラス',\n",
       " '導入',\n",
       " 'アジア',\n",
       " '全体',\n",
       " '全体',\n",
       " '全体',\n",
       " 'タイ',\n",
       " 'タイ',\n",
       " 'タイ',\n",
       " '普通',\n",
       " '普通',\n",
       " '一人',\n",
       " '長野',\n",
       " '施行',\n",
       " '舞台',\n",
       " '舞台',\n",
       " '一方',\n",
       " 'スペイン',\n",
       " '意見',\n",
       " '意見',\n",
       " '再び',\n",
       " '発見',\n",
       " '発見',\n",
       " '発見',\n",
       " '鈴木',\n",
       " 'ローマ',\n",
       " 'ローマ',\n",
       " 'ローマ',\n",
       " '保護',\n",
       " '保護',\n",
       " '保護',\n",
       " '少女',\n",
       " '少女',\n",
       " '試験',\n",
       " '試験',\n",
       " '試験',\n",
       " '多数',\n",
       " '多数',\n",
       " '反対',\n",
       " '反対',\n",
       " 'きく',\n",
       " '作家',\n",
       " '作家',\n",
       " '作家',\n",
       " '作家',\n",
       " '地球',\n",
       " '方法',\n",
       " '特徴',\n",
       " '特徴',\n",
       " '特徴',\n",
       " '特徴',\n",
       " 'ベース',\n",
       " 'ベース',\n",
       " '男性',\n",
       " '男性',\n",
       " '男性',\n",
       " 'ケース',\n",
       " 'ケース',\n",
       " '子供',\n",
       " '子供',\n",
       " '子供',\n",
       " '以来',\n",
       " '福島',\n",
       " '大臣',\n",
       " '大臣',\n",
       " 'オープン',\n",
       " '兵庫',\n",
       " 'コーナー',\n",
       " '取締役',\n",
       " '取締役',\n",
       " '人気',\n",
       " '人気',\n",
       " '評価',\n",
       " '評価',\n",
       " '評価',\n",
       " '評価',\n",
       " '評価',\n",
       " '説明',\n",
       " '説明',\n",
       " '説明',\n",
       " '装備',\n",
       " 'ドル',\n",
       " 'ドル',\n",
       " '投票',\n",
       " '投票',\n",
       " '雑誌',\n",
       " '雑誌',\n",
       " '熊本',\n",
       " 'グランド',\n",
       " '学科',\n",
       " '学科',\n",
       " 'パー',\n",
       " '専用',\n",
       " '登録',\n",
       " '登録',\n",
       " '登録',\n",
       " '登録',\n",
       " '佐藤',\n",
       " '田中',\n",
       " 'ソン',\n",
       " 'ステージ',\n",
       " 'ステージ',\n",
       " '沖縄',\n",
       " 'ゲスト',\n",
       " 'ゲスト',\n",
       " '学生',\n",
       " '学生',\n",
       " '周辺',\n",
       " '周辺',\n",
       " '言葉',\n",
       " '言葉',\n",
       " '教会',\n",
       " '教会',\n",
       " '内閣',\n",
       " '整備',\n",
       " '主張',\n",
       " '主張',\n",
       " '主張',\n",
       " 'ロック',\n",
       " 'ロック',\n",
       " '事故',\n",
       " '事故',\n",
       " '分類',\n",
       " '分類',\n",
       " '分類',\n",
       " '分類',\n",
       " '分類',\n",
       " '状況',\n",
       " '状況',\n",
       " '状況',\n",
       " '状況',\n",
       " '中村',\n",
       " '連載',\n",
       " '家族',\n",
       " '距離',\n",
       " '距離',\n",
       " '表現',\n",
       " '表現',\n",
       " '表現',\n",
       " '仙台',\n",
       " '新しい',\n",
       " 'ホール',\n",
       " 'ホール',\n",
       " '体重',\n",
       " '血液',\n",
       " '同意',\n",
       " '同意',\n",
       " 'これらの',\n",
       " '由来',\n",
       " '平均',\n",
       " '平均',\n",
       " '事実',\n",
       " '事実',\n",
       " '店舗',\n",
       " '店舗',\n",
       " '店舗',\n",
       " 'カテゴリ',\n",
       " 'カテゴリ',\n",
       " 'メートル',\n",
       " 'メートル',\n",
       " 'メートル',\n",
       " '芸術',\n",
       " '芸術',\n",
       " '主人公',\n",
       " '複数',\n",
       " '複数',\n",
       " '観光',\n",
       " '観光',\n",
       " '観光',\n",
       " '取得',\n",
       " '取得',\n",
       " '取得',\n",
       " '王国',\n",
       " '電話',\n",
       " '刑事',\n",
       " 'レコード',\n",
       " 'レコード',\n",
       " '秋田',\n",
       " '上記',\n",
       " 'トップ',\n",
       " '付近',\n",
       " 'リン',\n",
       " 'リン',\n",
       " '輸送',\n",
       " '輸送',\n",
       " '岐阜',\n",
       " '飛行',\n",
       " '長崎',\n",
       " 'メイン',\n",
       " 'メイン',\n",
       " 'メイン',\n",
       " 'ロード',\n",
       " 'エル',\n",
       " '札幌',\n",
       " 'ワールド',\n",
       " '美術',\n",
       " '息子',\n",
       " '息子',\n",
       " '制度',\n",
       " 'ツアー',\n",
       " 'ツアー',\n",
       " 'に関して',\n",
       " 'スタジオ',\n",
       " 'スタジオ',\n",
       " '市民',\n",
       " '市民',\n",
       " '市民',\n",
       " '松本',\n",
       " '同じく',\n",
       " '自然',\n",
       " '自然',\n",
       " 'マイル',\n",
       " 'マイル',\n",
       " '組合',\n",
       " '生徒',\n",
       " '生徒',\n",
       " '生徒',\n",
       " 'ギター',\n",
       " 'アップ',\n",
       " '転載',\n",
       " 'コース',\n",
       " 'コース',\n",
       " '防衛',\n",
       " '鹿児島',\n",
       " '変化',\n",
       " 'アナウンサー',\n",
       " 'タイプ',\n",
       " '議会',\n",
       " '石川',\n",
       " 'パリ',\n",
       " '南部',\n",
       " '南部',\n",
       " '経験',\n",
       " '経験',\n",
       " '延長',\n",
       " '延長',\n",
       " '延長',\n",
       " 'ランド',\n",
       " 'ランド',\n",
       " 'ランド',\n",
       " '条件',\n",
       " '条件',\n",
       " '条件',\n",
       " '条件',\n",
       " '伝説',\n",
       " '伝説',\n",
       " 'ロンドン',\n",
       " '本部',\n",
       " '本部',\n",
       " 'フリー',\n",
       " '競走',\n",
       " '競走',\n",
       " '高橋',\n",
       " 'デジタル',\n",
       " '山田',\n",
       " '台湾',\n",
       " 'ポジション',\n",
       " 'ポジション',\n",
       " '紀元前',\n",
       " 'インド',\n",
       " '吉田',\n",
       " '東海',\n",
       " '名誉',\n",
       " '名誉',\n",
       " 'ソング',\n",
       " 'ソング',\n",
       " 'ライン',\n",
       " '履歴',\n",
       " '方向',\n",
       " '方向',\n",
       " '方向',\n",
       " '法律',\n",
       " '法律',\n",
       " '提案',\n",
       " '提案',\n",
       " '提案',\n",
       " '提案',\n",
       " 'シティ',\n",
       " '効果',\n",
       " '効果',\n",
       " 'ミュージック',\n",
       " 'ヶ月',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from',\n",
       " 'as',\n",
       " 'japan',\n",
       " 'nippon',\n",
       " 'this',\n",
       " 'until',\n",
       " 'till',\n",
       " 'also',\n",
       " 'showa',\n",
       " 'things',\n",
       " 'universities',\n",
       " 'university',\n",
       " 'college',\n",
       " 'colleges',\n",
       " 'tv',\n",
       " 'televisions',\n",
       " 'television',\n",
       " 'broadcast',\n",
       " 'broadcasting',\n",
       " 'tokyo',\n",
       " 'than',\n",
       " 'deleted',\n",
       " 'deleting',\n",
       " 'deletion',\n",
       " 'remove',\n",
       " 'delete',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'present',\n",
       " 'heisei',\n",
       " 'schools',\n",
       " 'school',\n",
       " 'this',\n",
       " 'world',\n",
       " 'america',\n",
       " 'but',\n",
       " 'about',\n",
       " 'works',\n",
       " 'discography',\n",
       " 'era',\n",
       " 'movie',\n",
       " 'cinema',\n",
       " 'film',\n",
       " 'movies',\n",
       " 'director',\n",
       " 'supervision',\n",
       " 'railroads',\n",
       " 'railroad',\n",
       " 'railways',\n",
       " 'railway',\n",
       " 'use',\n",
       " 'appearances',\n",
       " 'appearance',\n",
       " 'cast',\n",
       " 'meiji',\n",
       " 'hours',\n",
       " 'hour',\n",
       " 'time',\n",
       " 'begin',\n",
       " 'start',\n",
       " 'initiation',\n",
       " 'series',\n",
       " 'only',\n",
       " 'article',\n",
       " 'story',\n",
       " 'stories',\n",
       " 'articles',\n",
       " 'activities',\n",
       " 'players',\n",
       " 'athletes',\n",
       " 'but',\n",
       " 'studies',\n",
       " 'research',\n",
       " 'conversation',\n",
       " 'conversations',\n",
       " 'osaka',\n",
       " 'convention',\n",
       " 'teams',\n",
       " 'team',\n",
       " 'existence',\n",
       " 'winning',\n",
       " 'lyrics',\n",
       " 'affiliation',\n",
       " 'belong',\n",
       " 'international',\n",
       " 'some',\n",
       " 'partially',\n",
       " 'result',\n",
       " 'results',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'bus',\n",
       " 'bass',\n",
       " 'buses',\n",
       " 'gaming',\n",
       " 'game',\n",
       " 'games',\n",
       " 'issue',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'issues',\n",
       " 'league',\n",
       " 'leagues',\n",
       " 'redeem',\n",
       " 'development',\n",
       " 'business',\n",
       " 'decision',\n",
       " 'decisions',\n",
       " 'music',\n",
       " 'forward',\n",
       " 'transfer',\n",
       " 'transmit',\n",
       " 'transfers',\n",
       " 'info',\n",
       " 'information',\n",
       " 'formula',\n",
       " 'official',\n",
       " 'join',\n",
       " 'participation',\n",
       " 'regions',\n",
       " 'region',\n",
       " 'changes',\n",
       " 'modify',\n",
       " 'change',\n",
       " 'arranger',\n",
       " 'arranged',\n",
       " 'arrangement',\n",
       " 'site',\n",
       " 'sites',\n",
       " 'chome',\n",
       " 'recording',\n",
       " 'record',\n",
       " 'relation',\n",
       " 'relations',\n",
       " 'club',\n",
       " 'clubs',\n",
       " 'chūō',\n",
       " 'central',\n",
       " 'center',\n",
       " 'centre',\n",
       " 'same',\n",
       " 'established',\n",
       " 'incorporation',\n",
       " 'establishment',\n",
       " 'thinking',\n",
       " 'thoughts',\n",
       " 'education',\n",
       " 'pro',\n",
       " 'installation',\n",
       " 'announcement',\n",
       " 'announcements',\n",
       " 'elementary',\n",
       " 'edit',\n",
       " 'edits',\n",
       " 'editing',\n",
       " 'modify',\n",
       " 'season',\n",
       " 'seasons',\n",
       " 'files',\n",
       " 'file',\n",
       " 'france',\n",
       " 'city',\n",
       " 'cities',\n",
       " 'publisher',\n",
       " 'publishing',\n",
       " 'publication',\n",
       " 'firm',\n",
       " 'company',\n",
       " 'companies',\n",
       " 'centuries',\n",
       " 'century',\n",
       " 'note',\n",
       " 'notebooks',\n",
       " 'notes',\n",
       " 'notebook',\n",
       " 'kyoto',\n",
       " 'society',\n",
       " 'societies',\n",
       " 'germany',\n",
       " 'held',\n",
       " 'single',\n",
       " 'center',\n",
       " 'centre',\n",
       " 'quit',\n",
       " 'finish',\n",
       " 'end',\n",
       " 'finished',\n",
       " 'exit',\n",
       " 'center',\n",
       " 'centre',\n",
       " 'content',\n",
       " 'contents',\n",
       " 'culture',\n",
       " 'england',\n",
       " 'uk',\n",
       " 'drama',\n",
       " 'dramas',\n",
       " 'further',\n",
       " 'china',\n",
       " 'cinematography',\n",
       " 'photography',\n",
       " 'filming',\n",
       " 'championships',\n",
       " 'championship',\n",
       " 'baseball',\n",
       " 'designation',\n",
       " 'specify',\n",
       " 'position',\n",
       " 'below',\n",
       " 'mann',\n",
       " 'graduated',\n",
       " 'graduating',\n",
       " 'graduation',\n",
       " 'person',\n",
       " 'bunko',\n",
       " 'public',\n",
       " 'publish',\n",
       " 'hokkaido',\n",
       " 'hokkaidō',\n",
       " 'last',\n",
       " 'final',\n",
       " 'anime',\n",
       " 'confirmation',\n",
       " 'confirm',\n",
       " 'general',\n",
       " 'history',\n",
       " 'election',\n",
       " 'elections',\n",
       " 'planned',\n",
       " 'planning',\n",
       " 'plan',\n",
       " 'plans',\n",
       " 'economies',\n",
       " 'economy',\n",
       " 'page',\n",
       " 'pages',\n",
       " 'professor',\n",
       " 'kinen',\n",
       " 'radio',\n",
       " 'theater',\n",
       " 'theatre',\n",
       " 'group',\n",
       " 'groups',\n",
       " 'english',\n",
       " 'woman',\n",
       " 'female',\n",
       " 'women',\n",
       " 'district',\n",
       " 'earn',\n",
       " 'score',\n",
       " 'comment',\n",
       " 'commenting',\n",
       " 'commented',\n",
       " 'comments',\n",
       " 'comics',\n",
       " 'manga',\n",
       " 'others',\n",
       " 'herself',\n",
       " 'assumption',\n",
       " 'abolished',\n",
       " 'abolition',\n",
       " 'selling',\n",
       " 'sales',\n",
       " 'attacks',\n",
       " 'attack',\n",
       " 'soccer',\n",
       " 'lee',\n",
       " 'senator',\n",
       " 'nationwide',\n",
       " 'debut',\n",
       " 'association',\n",
       " 'routes',\n",
       " 'fuji',\n",
       " 'myself',\n",
       " 'war',\n",
       " 'wars',\n",
       " 'production',\n",
       " 'part',\n",
       " 'highschool',\n",
       " 'number',\n",
       " 'initially',\n",
       " 'first',\n",
       " 'awards',\n",
       " 'award',\n",
       " 'duration',\n",
       " 'period',\n",
       " 'hiroshima',\n",
       " 'place',\n",
       " 'location',\n",
       " 'places',\n",
       " 'technology',\n",
       " 'navy',\n",
       " 'link',\n",
       " 'links',\n",
       " 'merger',\n",
       " 'mergers',\n",
       " 'or',\n",
       " 'roads',\n",
       " 'road',\n",
       " 'specific',\n",
       " 'specified',\n",
       " 'asahi',\n",
       " 'meaning',\n",
       " 'meanings',\n",
       " 'system',\n",
       " 'systems',\n",
       " 'models',\n",
       " 'model',\n",
       " 'correspondence',\n",
       " 'train',\n",
       " 'trains',\n",
       " 'construction',\n",
       " 'when',\n",
       " 'last',\n",
       " 'science',\n",
       " 'reasons',\n",
       " 'reason',\n",
       " 'and',\n",
       " 'one',\n",
       " 'taisho',\n",
       " 'taishō',\n",
       " 'best',\n",
       " 'blocks',\n",
       " 'block',\n",
       " 'vehicles',\n",
       " 'vehicle',\n",
       " 'car',\n",
       " 'automobile',\n",
       " 'populations',\n",
       " 'population',\n",
       " 'particularly',\n",
       " 'especially',\n",
       " 'business',\n",
       " 'occurrence',\n",
       " 'newspaper',\n",
       " 'newspapers',\n",
       " 'continuity',\n",
       " 'continuous',\n",
       " 'government',\n",
       " 'configuration',\n",
       " 'composition',\n",
       " 'structure',\n",
       " 'configurations',\n",
       " 'maximum',\n",
       " 'largest',\n",
       " 'character',\n",
       " 'characters',\n",
       " 'novel',\n",
       " 'novels',\n",
       " 'each',\n",
       " 'organs',\n",
       " 'institution',\n",
       " 'institutions',\n",
       " 'reference',\n",
       " 'references',\n",
       " 'referencing',\n",
       " 'member',\n",
       " 'members',\n",
       " 'issued',\n",
       " 'issuing',\n",
       " 'issuance',\n",
       " 'issue',\n",
       " 'images',\n",
       " 'picture',\n",
       " 'image',\n",
       " 'pictorial',\n",
       " 'state',\n",
       " 'condition',\n",
       " 'denomination',\n",
       " 'name',\n",
       " 'names',\n",
       " 'dam',\n",
       " 'home',\n",
       " 'operation',\n",
       " 'post',\n",
       " 'posts',\n",
       " 'posting',\n",
       " 'name',\n",
       " 'names',\n",
       " 'fukuoka',\n",
       " 'facilities',\n",
       " 'institution',\n",
       " 'facility',\n",
       " 'surveys',\n",
       " 'investigation',\n",
       " 'survey',\n",
       " 'manufactured',\n",
       " 'italy',\n",
       " 'russian',\n",
       " 'russia',\n",
       " 'independent',\n",
       " 'independence',\n",
       " 'monogatari',\n",
       " 'story',\n",
       " 'narrative',\n",
       " 'shrines',\n",
       " 'shrine',\n",
       " 'jinja',\n",
       " 'planning',\n",
       " 'san',\n",
       " 'nagoya',\n",
       " 'normally',\n",
       " 'usually',\n",
       " 'enterprise',\n",
       " 'aviation',\n",
       " 'air',\n",
       " 'super',\n",
       " 'empire',\n",
       " 'tonne',\n",
       " 'tons',\n",
       " 'ton',\n",
       " 'tonnes',\n",
       " 'influence',\n",
       " 'influences',\n",
       " 'victories',\n",
       " 'win',\n",
       " 'wins',\n",
       " 'victory',\n",
       " 'winning',\n",
       " 'designs',\n",
       " 'design',\n",
       " 'designing',\n",
       " 'everything',\n",
       " 'headquarters',\n",
       " 'human',\n",
       " 'chiba',\n",
       " 'anne',\n",
       " 'ang',\n",
       " 'ann',\n",
       " 'traffic',\n",
       " 'transportation',\n",
       " 'transport',\n",
       " 'organization',\n",
       " 'organisation',\n",
       " 'structures',\n",
       " 'structure',\n",
       " 'battle',\n",
       " 'implementation',\n",
       " 'here',\n",
       " 'formerly',\n",
       " 'before',\n",
       " 'services',\n",
       " 'service',\n",
       " 'consolidate',\n",
       " 'integrated',\n",
       " 'merge',\n",
       " 'integration',\n",
       " 'integrations',\n",
       " 'themes',\n",
       " 'theme',\n",
       " 'area',\n",
       " 'engine',\n",
       " 'engines',\n",
       " 'starring',\n",
       " 'bill',\n",
       " 'japanese',\n",
       " 'contracts',\n",
       " 'contract',\n",
       " 'preferences',\n",
       " 'settings',\n",
       " 'setup',\n",
       " 'configuration',\n",
       " 'configure',\n",
       " 'live',\n",
       " 'contains',\n",
       " 'includes',\n",
       " 'including',\n",
       " 'expertise',\n",
       " 'specialized',\n",
       " 'function',\n",
       " 'features',\n",
       " 'feature',\n",
       " 'functionality',\n",
       " 'height',\n",
       " 'locations',\n",
       " 'location',\n",
       " 'completion',\n",
       " 'notation',\n",
       " 'driving',\n",
       " 'photo',\n",
       " 'photography',\n",
       " 'photograph',\n",
       " 'picture',\n",
       " 'relevant',\n",
       " 'related',\n",
       " 'bookstore',\n",
       " 'high',\n",
       " 'tall',\n",
       " 'expensive',\n",
       " 'production',\n",
       " 'yokohama',\n",
       " 'above',\n",
       " 'universe',\n",
       " 'management',\n",
       " 'manage',\n",
       " 'bars',\n",
       " 'bar',\n",
       " 'john',\n",
       " 'troop',\n",
       " 'park',\n",
       " 'parks',\n",
       " 'sport',\n",
       " 'sports',\n",
       " 'screenplay',\n",
       " 'script',\n",
       " 'objectives',\n",
       " 'aims',\n",
       " 'purpose',\n",
       " 'objective',\n",
       " 'life',\n",
       " 'cards',\n",
       " 'card',\n",
       " 'fundamentals',\n",
       " 'basics',\n",
       " 'basic',\n",
       " 'niigata',\n",
       " 'actresses',\n",
       " 'actress',\n",
       " 'unknown',\n",
       " 'titles',\n",
       " 'title',\n",
       " 'politics',\n",
       " 'electricity',\n",
       " 'electric',\n",
       " 'police',\n",
       " 'create',\n",
       " 'creation',\n",
       " 'created',\n",
       " 'gun',\n",
       " 'scheduled',\n",
       " 'planned',\n",
       " 'star',\n",
       " 'management',\n",
       " 'freedom',\n",
       " 'liberty',\n",
       " 'free',\n",
       " 'freedoms',\n",
       " 'past',\n",
       " 'army',\n",
       " 'operation',\n",
       " 'aichi',\n",
       " 'view',\n",
       " 'president',\n",
       " 'presidents',\n",
       " 'organizations',\n",
       " 'organization',\n",
       " 'industrial',\n",
       " 'street',\n",
       " 'external',\n",
       " 'correspondence',\n",
       " 'communication',\n",
       " 'communications',\n",
       " 'al',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actor',\n",
       " 'special',\n",
       " 'boy',\n",
       " 'hospital',\n",
       " 'hospitals',\n",
       " 'marriage',\n",
       " 'marriages',\n",
       " 'personal',\n",
       " 'individual',\n",
       " 'individuals',\n",
       " 'interval',\n",
       " 'banking',\n",
       " 'bank',\n",
       " 'institute',\n",
       " 'mainly',\n",
       " 'primarily',\n",
       " 'gakuen',\n",
       " 'she',\n",
       " 'news',\n",
       " 'other',\n",
       " 'others',\n",
       " 'soft',\n",
       " 'literature',\n",
       " 'ability',\n",
       " 'none',\n",
       " 'without',\n",
       " 'edo',\n",
       " 'scholar',\n",
       " 'scholars',\n",
       " 'domestic',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'york',\n",
       " 'fast',\n",
       " 'languages',\n",
       " 'language',\n",
       " 'design',\n",
       " 'korea',\n",
       " 'release',\n",
       " 'releases',\n",
       " 'vest',\n",
       " 'best',\n",
       " 'contemporary',\n",
       " 'conference',\n",
       " 'meetings',\n",
       " 'meeting',\n",
       " 'band',\n",
       " 'bands',\n",
       " 'add',\n",
       " 'adds',\n",
       " 'append',\n",
       " 'successful',\n",
       " 'success',\n",
       " 'move',\n",
       " 'moving',\n",
       " 'olympics',\n",
       " 'national',\n",
       " 'nation',\n",
       " 'fans',\n",
       " 'fan',\n",
       " 'everything',\n",
       " 'all',\n",
       " 'yamaguchi',\n",
       " 'exercise',\n",
       " 'movement',\n",
       " 'environment',\n",
       " 'environments',\n",
       " 'inauguration',\n",
       " 'big',\n",
       " 'competition',\n",
       " 'chairperson',\n",
       " 'chairman',\n",
       " 'europe',\n",
       " 'introduction',\n",
       " 'referral',\n",
       " 'form',\n",
       " 'factories',\n",
       " 'factory',\n",
       " 'opponent',\n",
       " 'battle',\n",
       " 'combat',\n",
       " 'labour',\n",
       " 'labor',\n",
       " 'office',\n",
       " 'limited',\n",
       " 'data',\n",
       " 'operation',\n",
       " 'originality',\n",
       " 'original',\n",
       " 'originals',\n",
       " 'possibilities',\n",
       " 'possible',\n",
       " 'possibility',\n",
       " 'staging',\n",
       " 'kinds',\n",
       " 'type',\n",
       " 'types',\n",
       " 'character',\n",
       " 'characters',\n",
       " 'president',\n",
       " 'cooperation',\n",
       " 'guidance',\n",
       " 'judgement',\n",
       " 'judgment',\n",
       " 'federation',\n",
       " 'net',\n",
       " 'nets',\n",
       " 'republic',\n",
       " 'retire',\n",
       " 'retiring',\n",
       " 'retired',\n",
       " 'department',\n",
       " 'industry',\n",
       " 'final',\n",
       " 'producers',\n",
       " 'producer',\n",
       " 'lineage',\n",
       " 'births',\n",
       " 'birth',\n",
       " 'command',\n",
       " 'commanding',\n",
       " 'race',\n",
       " 'racing',\n",
       " 'lace',\n",
       " 'shizuoka',\n",
       " 'mail',\n",
       " 'kanagawa',\n",
       " 'okayama',\n",
       " 'saitama',\n",
       " 'entries',\n",
       " 'cups',\n",
       " 'cup',\n",
       " 'run',\n",
       " 'ray',\n",
       " 'transfer',\n",
       " 'relocation',\n",
       " 'almost',\n",
       " 'nearly',\n",
       " 'intersection',\n",
       " 'events',\n",
       " 'event',\n",
       " 'horseracing',\n",
       " 'different',\n",
       " 'differing',\n",
       " 'kobe',\n",
       " 'kerr',\n",
       " 'sources',\n",
       " 'source',\n",
       " 'kansai',\n",
       " 'almost',\n",
       " 'behaviour',\n",
       " 'behavioural',\n",
       " 'behavior',\n",
       " 'behavioral',\n",
       " 'important',\n",
       " 'project',\n",
       " 'projects',\n",
       " 'kyūshū',\n",
       " 'kyushu',\n",
       " 'train',\n",
       " 'trains',\n",
       " 'architecture',\n",
       " 'classes',\n",
       " 'class',\n",
       " 'introduction',\n",
       " 'asia',\n",
       " 'overall',\n",
       " 'whole',\n",
       " 'entire',\n",
       " 'thailand',\n",
       " 'tai',\n",
       " 'ty',\n",
       " 'ordinary',\n",
       " 'normal',\n",
       " 'one',\n",
       " 'nagano',\n",
       " 'enforced',\n",
       " 'stages',\n",
       " 'stage',\n",
       " 'meanwhile',\n",
       " 'spain',\n",
       " 'opinion',\n",
       " 'opinions',\n",
       " 'again',\n",
       " 'discovering',\n",
       " 'discover',\n",
       " 'discovery',\n",
       " 'suzuki',\n",
       " 'roman',\n",
       " 'rome',\n",
       " 'roma',\n",
       " 'protecting',\n",
       " 'protect',\n",
       " 'protection',\n",
       " 'girl',\n",
       " 'shōjo',\n",
       " 'examination',\n",
       " 'exam',\n",
       " 'exams',\n",
       " 'many',\n",
       " 'numerous',\n",
       " 'against',\n",
       " 'opposite',\n",
       " 'ets',\n",
       " 'authors',\n",
       " 'writer',\n",
       " 'writers',\n",
       " 'author',\n",
       " 'earth',\n",
       " 'method',\n",
       " 'characteristics',\n",
       " 'features',\n",
       " 'feature',\n",
       " 'characteristic',\n",
       " 'base',\n",
       " 'bass',\n",
       " 'male',\n",
       " 'men',\n",
       " 'man',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'kids',\n",
       " 'children',\n",
       " 'child',\n",
       " 'since',\n",
       " 'fukushima',\n",
       " 'minister',\n",
       " 'ministers',\n",
       " 'open',\n",
       " 'hyogo',\n",
       " 'corner',\n",
       " 'director',\n",
       " 'directors',\n",
       " 'popular',\n",
       " 'popularity',\n",
       " 'rating',\n",
       " 'ratings',\n",
       " 'evaluation',\n",
       " 'rate',\n",
       " 'assessment',\n",
       " 'explanation',\n",
       " 'explain',\n",
       " 'description',\n",
       " 'equipment',\n",
       " 'dollars',\n",
       " 'dollar',\n",
       " 'vote',\n",
       " 'voting',\n",
       " 'magazine',\n",
       " 'magazines',\n",
       " 'kumamoto',\n",
       " 'grand',\n",
       " 'department',\n",
       " 'departments',\n",
       " 'par',\n",
       " 'dedicated',\n",
       " 'register',\n",
       " 'signup',\n",
       " 'registrations',\n",
       " 'registration',\n",
       " 'sato',\n",
       " 'tanaka',\n",
       " 'sơn',\n",
       " 'stages',\n",
       " 'stage',\n",
       " 'okinawa',\n",
       " 'guest',\n",
       " 'guests',\n",
       " 'students',\n",
       " 'student',\n",
       " 'surroundings',\n",
       " 'periphery',\n",
       " 'word',\n",
       " 'words',\n",
       " 'churches',\n",
       " 'church',\n",
       " 'cabinet',\n",
       " 'maintenance',\n",
       " 'claim',\n",
       " 'assertion',\n",
       " 'allegation',\n",
       " 'lock',\n",
       " 'rock',\n",
       " 'accident',\n",
       " 'accidents',\n",
       " 'category',\n",
       " 'categorization',\n",
       " 'classifications',\n",
       " 'categories',\n",
       " 'classification',\n",
       " 'circumstance',\n",
       " 'situations',\n",
       " 'situation',\n",
       " 'circumstances',\n",
       " 'nakamura',\n",
       " 'serialized',\n",
       " 'family',\n",
       " 'distance',\n",
       " 'distances',\n",
       " 'representation',\n",
       " 'expression',\n",
       " 'representations',\n",
       " 'sendai',\n",
       " 'new',\n",
       " 'hole',\n",
       " 'hall',\n",
       " 'weight',\n",
       " 'blood',\n",
       " 'consent',\n",
       " 'agreed',\n",
       " 'these',\n",
       " 'origin',\n",
       " 'average',\n",
       " 'mean',\n",
       " 'facts',\n",
       " 'fact',\n",
       " 'stores',\n",
       " 'shops',\n",
       " 'store',\n",
       " 'category',\n",
       " 'categories',\n",
       " 'meters',\n",
       " 'metre',\n",
       " 'metres',\n",
       " 'arts',\n",
       " 'art',\n",
       " 'protagonist',\n",
       " 'multiple',\n",
       " 'plural',\n",
       " 'tourism',\n",
       " 'tourist',\n",
       " 'sightseeing',\n",
       " 'claim',\n",
       " 'retrieve',\n",
       " 'fetch',\n",
       " 'kingdom',\n",
       " 'telephone',\n",
       " 'detective',\n",
       " 'record',\n",
       " 'records',\n",
       " 'akita',\n",
       " 'above',\n",
       " 'top',\n",
       " 'near',\n",
       " 'lynn',\n",
       " 'phosphorus',\n",
       " 'transportation',\n",
       " 'transport',\n",
       " 'gifu',\n",
       " 'flight',\n",
       " 'nagasaki',\n",
       " 'main',\n",
       " 'maine',\n",
       " 'primary',\n",
       " 'load',\n",
       " 'elle',\n",
       " 'sapporo',\n",
       " 'world',\n",
       " 'art',\n",
       " 'sons',\n",
       " 'son',\n",
       " 'institution',\n",
       " 'tour',\n",
       " 'tours',\n",
       " 'concerning',\n",
       " 'studios',\n",
       " 'studio',\n",
       " 'citizens',\n",
       " 'citizenship',\n",
       " 'citizen',\n",
       " 'matsumoto',\n",
       " 'likewise',\n",
       " 'natural',\n",
       " 'nature',\n",
       " 'miles',\n",
       " 'mile',\n",
       " 'associations',\n",
       " 'students',\n",
       " 'pupil',\n",
       " 'student',\n",
       " 'guitar',\n",
       " 'up',\n",
       " 'reposted',\n",
       " 'course',\n",
       " 'courses',\n",
       " 'defense',\n",
       " 'kagoshima',\n",
       " 'change',\n",
       " 'announcer',\n",
       " 'type',\n",
       " 'parliament',\n",
       " 'ishikawa',\n",
       " 'paris',\n",
       " 'nambu',\n",
       " 'southern',\n",
       " 'experienced',\n",
       " 'experience',\n",
       " 'extended',\n",
       " 'extend',\n",
       " 'extension',\n",
       " 'rand',\n",
       " 'land',\n",
       " 'lando',\n",
       " 'conditional',\n",
       " 'criteria',\n",
       " 'conditions',\n",
       " 'condition',\n",
       " 'legend',\n",
       " 'legendary',\n",
       " 'london',\n",
       " 'hq',\n",
       " 'headquarters',\n",
       " 'free',\n",
       " 'race',\n",
       " 'racing',\n",
       " 'takahashi',\n",
       " 'digital',\n",
       " 'yamada',\n",
       " 'taiwan',\n",
       " 'position',\n",
       " 'positions',\n",
       " 'bc',\n",
       " 'india',\n",
       " 'yoshida',\n",
       " 'tokai',\n",
       " 'honour',\n",
       " 'honor',\n",
       " 'songs',\n",
       " 'song',\n",
       " 'line',\n",
       " 'history',\n",
       " 'directions',\n",
       " 'direction',\n",
       " 'orientation',\n",
       " 'law',\n",
       " 'laws',\n",
       " 'suggest',\n",
       " 'suggestions',\n",
       " 'suggestion',\n",
       " 'proposal',\n",
       " 'city',\n",
       " 'effect',\n",
       " 'effects',\n",
       " 'music',\n",
       " 'months',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.DataFrame()\n",
    "pairs['source'] = pd.Series(sources)\n",
    "pairs['target'] = pd.Series(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>から</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>として</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>日本</td>\n",
       "      <td>japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>日本</td>\n",
       "      <td>nippon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>この</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>まで</td>\n",
       "      <td>until</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>まで</td>\n",
       "      <td>till</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>また</td>\n",
       "      <td>also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>昭和</td>\n",
       "      <td>showa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>もの</td>\n",
       "      <td>things</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>大学</td>\n",
       "      <td>universities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>大学</td>\n",
       "      <td>university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>大学</td>\n",
       "      <td>college</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>大学</td>\n",
       "      <td>colleges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>テレビ</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>テレビ</td>\n",
       "      <td>televisions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>テレビ</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>放送</td>\n",
       "      <td>broadcast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>放送</td>\n",
       "      <td>broadcasting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>東京</td>\n",
       "      <td>tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>より</td>\n",
       "      <td>than</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>削除</td>\n",
       "      <td>deleted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>削除</td>\n",
       "      <td>deleting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>削除</td>\n",
       "      <td>deletion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>削除</td>\n",
       "      <td>remove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>削除</td>\n",
       "      <td>delete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>現在</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>現在</td>\n",
       "      <td>currently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>現在</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>平成</td>\n",
       "      <td>heisei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25939</th>\n",
       "      <td>シンチレータ</td>\n",
       "      <td>scintillator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25940</th>\n",
       "      <td>シュレフ</td>\n",
       "      <td>chlef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25941</th>\n",
       "      <td>ウーゾ</td>\n",
       "      <td>ouzo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25942</th>\n",
       "      <td>ハニーポット</td>\n",
       "      <td>honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25943</th>\n",
       "      <td>プナカ</td>\n",
       "      <td>punakha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25944</th>\n",
       "      <td>ラクターゼ</td>\n",
       "      <td>lactase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25945</th>\n",
       "      <td>ムネ</td>\n",
       "      <td>breasted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25946</th>\n",
       "      <td>ビホルダー</td>\n",
       "      <td>beholder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25947</th>\n",
       "      <td>ウィギン</td>\n",
       "      <td>wiggin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25948</th>\n",
       "      <td>ウスパルタ</td>\n",
       "      <td>isparta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25949</th>\n",
       "      <td>ズーランダー</td>\n",
       "      <td>zoolander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25950</th>\n",
       "      <td>サラート</td>\n",
       "      <td>salah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25951</th>\n",
       "      <td>ハテム</td>\n",
       "      <td>hatem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25952</th>\n",
       "      <td>ロカテッリ</td>\n",
       "      <td>locatelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25953</th>\n",
       "      <td>フロレンシア</td>\n",
       "      <td>florencia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25954</th>\n",
       "      <td>イェヴレ</td>\n",
       "      <td>gävle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25955</th>\n",
       "      <td>ヴォルテッラ</td>\n",
       "      <td>volterra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25956</th>\n",
       "      <td>エリスタ</td>\n",
       "      <td>elista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25957</th>\n",
       "      <td>エラズー</td>\n",
       "      <td>elazığ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25958</th>\n",
       "      <td>ナーイ</td>\n",
       "      <td>ney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25959</th>\n",
       "      <td>パニール</td>\n",
       "      <td>paneer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25960</th>\n",
       "      <td>アイデム</td>\n",
       "      <td>idem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25961</th>\n",
       "      <td>ピーティー</td>\n",
       "      <td>petey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25962</th>\n",
       "      <td>リンデル</td>\n",
       "      <td>linder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25963</th>\n",
       "      <td>ビロビジャン</td>\n",
       "      <td>birobidzhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25964</th>\n",
       "      <td>ビヨーン</td>\n",
       "      <td>bjorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25965</th>\n",
       "      <td>アラカジュ</td>\n",
       "      <td>aracaju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25966</th>\n",
       "      <td>ミカル</td>\n",
       "      <td>michal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25967</th>\n",
       "      <td>オプティマイザ</td>\n",
       "      <td>optimizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25968</th>\n",
       "      <td>レムシャイト</td>\n",
       "      <td>remscheid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25969 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source        target\n",
       "0           から          from\n",
       "1          として            as\n",
       "2           日本         japan\n",
       "3           日本        nippon\n",
       "4           この          this\n",
       "5           まで         until\n",
       "6           まで          till\n",
       "7           また          also\n",
       "8           昭和         showa\n",
       "9           もの        things\n",
       "10          大学  universities\n",
       "11          大学    university\n",
       "12          大学       college\n",
       "13          大学      colleges\n",
       "14         テレビ            tv\n",
       "15         テレビ   televisions\n",
       "16         テレビ    television\n",
       "17          放送     broadcast\n",
       "18          放送  broadcasting\n",
       "19          東京         tokyo\n",
       "20          より          than\n",
       "21          削除       deleted\n",
       "22          削除      deleting\n",
       "23          削除      deletion\n",
       "24          削除        remove\n",
       "25          削除        delete\n",
       "26          現在       current\n",
       "27          現在     currently\n",
       "28          現在       present\n",
       "29          平成        heisei\n",
       "...        ...           ...\n",
       "25939   シンチレータ  scintillator\n",
       "25940     シュレフ         chlef\n",
       "25941      ウーゾ          ouzo\n",
       "25942   ハニーポット      honeypot\n",
       "25943      プナカ       punakha\n",
       "25944    ラクターゼ       lactase\n",
       "25945       ムネ      breasted\n",
       "25946    ビホルダー      beholder\n",
       "25947     ウィギン        wiggin\n",
       "25948    ウスパルタ       isparta\n",
       "25949   ズーランダー     zoolander\n",
       "25950     サラート         salah\n",
       "25951      ハテム         hatem\n",
       "25952    ロカテッリ     locatelli\n",
       "25953   フロレンシア     florencia\n",
       "25954     イェヴレ         gävle\n",
       "25955   ヴォルテッラ      volterra\n",
       "25956     エリスタ        elista\n",
       "25957     エラズー        elazığ\n",
       "25958      ナーイ           ney\n",
       "25959     パニール        paneer\n",
       "25960     アイデム          idem\n",
       "25961    ピーティー         petey\n",
       "25962     リンデル        linder\n",
       "25963   ビロビジャン   birobidzhan\n",
       "25964     ビヨーン         bjorn\n",
       "25965    アラカジュ       aracaju\n",
       "25966      ミカル        michal\n",
       "25967  オプティマイザ     optimizer\n",
       "25968   レムシャイト     remscheid\n",
       "\n",
       "[25969 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing missing vocabulary...\n",
      "Amount of missing vocab:  17016\n"
     ]
    }
   ],
   "source": [
    "print('Removing missing vocabulary...')\n",
    "\n",
    "missing = 0\n",
    "\n",
    "for n in range (len(pairs)):\n",
    "    if pairs['source'][n] not in model_source.wv.vocab or pairs['target'][n] not in model_target.wv.vocab:\n",
    "        missing = missing + 1\n",
    "        pairs = pairs.drop(n)\n",
    "\n",
    "pairs = pairs.reset_index(drop = True)\n",
    "print ('Amount of missing vocab: ', missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of pair words, excluding the missing vocabs \n",
    "# removed in previous step\n",
    "pairs['vector_source'] = [model_source[pairs['source'][n]] for n in range (len(pairs))]\n",
    "pairs['vector_target'] = [model_target[pairs['target'][n]] for n in range (len(pairs))]\n",
    "\n",
    "# first 5000 from both languages, to train translation matrix\n",
    "source_training_set = pairs['vector_source'][:10000]\n",
    "target_training_set = pairs['vector_target'][:10000]\n",
    "\n",
    "matrix_train_source = pd.DataFrame(source_training_set.tolist()).values\n",
    "matrix_train_target = pd.DataFrame(target_training_set.tolist()).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8953, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_train_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating translation matrix\n",
      "Generated translation matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Generating translation matrix')\n",
    "# Matrix W is given in  http://stackoverflow.com/questions/27980159/fit-a-linear-transformation-in-python\n",
    "translation_matrix = np.linalg.pinv(matrix_train_source).dot(matrix_train_target).T\n",
    "print ('Generated translation matrix')\n",
    "translation_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list of topn closest vectors to vectenter\n",
    "def most_similar_vector(self, vectenter, topn=5):\n",
    "    self.init_sims()\n",
    "    dists = np.dot(self.wv.syn0norm, vectenter)\n",
    "    if not topn:\n",
    "        return dists\n",
    "    best = np.argsort(dists)[::-1][:topn ]\n",
    "        # ignore (don't return) words from the input\n",
    "    result = [(self.wv.index2word[sim], float(dists[sim])) for sim in best]\n",
    "    return result[:topn]\n",
    "\n",
    "def top_translations(w,numb=5):\n",
    "    val = most_similar_vector(model_target,translation_matrix.dot(model_source[w]),numb)\n",
    "    #print 'traducwithscofres ', val\n",
    "    return val\n",
    "\n",
    "\n",
    "def top_translations_list(w, numb=5):\n",
    "    val = [top_translations(w,numb)[k][0] for k in range(numb)]\n",
    "    return val\n",
    "\n",
    "temp = 1\n",
    "#top_matches = [ pairs['target'][n] in top_translations_list(pairs['source'][n]) for n in range(5000,5003)] \n",
    "\n",
    "# print out source word and translation\n",
    "def display_translations():\n",
    "    for word_num in range(range_start, range_end):\n",
    "        source_word =  pairs['source'][word_num]\n",
    "        translations = top_translations_list(pairs['source'][word_num]) \n",
    "        print (source_word, translations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy @5 is  34 / 1000\n",
      "Accuracy @1 is  16 / 1000\n"
     ]
    }
   ],
   "source": [
    "# range to use to check accuracy\n",
    "range_start = 7000\n",
    "range_end = 8000\n",
    "\n",
    "#display_translations()\n",
    "\n",
    "# now we can check for accuracy on words 5000-6000, 1-5000 used to traning\n",
    "# translation matrix\n",
    "\n",
    "# returns matrix of true or false, true if translation is accuracy, false if not\n",
    "# accurate means the first translation (most similiar vector in target language)\n",
    "# is identical\n",
    "accuracy_at_five = [pairs['target'][n] in top_translations_list(pairs['source'][n]) for n in range(range_start, range_end)]\n",
    "print ('Accuracy @5 is ', sum(accuracy_at_five), '/', len(accuracy_at_five))\n",
    "\n",
    "accuracy_at_one = [pairs['target'][n] in top_translations_list(pairs['source'][n],1) for n in range(range_start, range_end)]\n",
    "print ('Accuracy @1 is ', sum(accuracy_at_one), '/', len(accuracy_at_one))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3636363636363638"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "52/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy @10 is  42 / 1000\n"
     ]
    }
   ],
   "source": [
    "accuracy_at_ten = [pairs['target'][n] in top_translations_list(pairs['source'][n],10) for n in range(range_start, range_end)]\n",
    "print ('Accuracy @10 is ', sum(accuracy_at_ten), '/', len(accuracy_at_ten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy @20 is  45 / 1000\n"
     ]
    }
   ],
   "source": [
    "accuracy_at_ten = [pairs['target'][n] in top_translations_list(pairs['source'][n],20) for n in range(range_start, range_end)]\n",
    "print ('Accuracy @20 is ', sum(accuracy_at_ten), '/', len(accuracy_at_ten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"jp_en.npy\",translation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-15 17:51:51,891 : INFO : loading Word2Vec object from model_CBOW_zh_wzh_2.w2v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-15 17:51:52,957 : INFO : loading wv recursively from model_CBOW_zh_wzh_2.w2v.wv.* with mmap=None\n",
      "2018-05-15 17:51:52,958 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-05-15 17:51:52,959 : INFO : setting ignored attribute cum_table to None\n",
      "2018-05-15 17:51:52,959 : INFO : loaded model_CBOW_zh_wzh_2.w2v\n",
      "2018-05-15 17:51:53,332 : INFO : loading Word2Vec object from model_CBOW_en_wzh_2.w2v\n",
      "2018-05-15 17:51:53,578 : INFO : loading wv recursively from model_CBOW_en_wzh_2.w2v.wv.* with mmap=None\n",
      "2018-05-15 17:51:53,579 : INFO : loading syn0 from model_CBOW_en_wzh_2.w2v.wv.syn0.npy with mmap=None\n",
      "2018-05-15 17:51:53,688 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-05-15 17:51:53,689 : INFO : loading syn1neg from model_CBOW_en_wzh_2.w2v.syn1neg.npy with mmap=None\n",
      "2018-05-15 17:51:53,804 : INFO : setting ignored attribute cum_table to None\n",
      "2018-05-15 17:51:53,805 : INFO : loaded model_CBOW_en_wzh_2.w2v\n"
     ]
    }
   ],
   "source": [
    "# models trained using gensim implementation of word2vec\n",
    "print('Loading models...')\n",
    "model_source = gensim.models.Word2Vec.load('model_CBOW_zh_wzh_2.w2v')\n",
    "model_target = gensim.models.Word2Vec.load('model_CBOW_en_wzh_2.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "targets = []\n",
    "with open(\"./zh-en.txt\",'r',encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        source,target = line.split()\n",
    "        sources.append(source)\n",
    "        targets.append(target)\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.DataFrame()\n",
    "pairs['source'] = pd.Series(sources)\n",
    "pairs['target'] = pd.Series(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>年</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>月</td>\n",
       "      <td>moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>月</td>\n",
       "      <td>months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>月</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>日</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>和</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>村</td>\n",
       "      <td>village</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>人</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>人</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>%</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>小行星</td>\n",
       "      <td>asteroids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>小行星</td>\n",
       "      <td>asteroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>大</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>他</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>德</td>\n",
       "      <td>tak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>重</td>\n",
       "      <td>heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>重</td>\n",
       "      <td>heavier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>一</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>定向</td>\n",
       "      <td>orientation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>定向</td>\n",
       "      <td>directional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>但</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>也</td>\n",
       "      <td>also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>拉</td>\n",
       "      <td>pull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>後</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>留言</td>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>市</td>\n",
       "      <td>city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>市</td>\n",
       "      <td>municipality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>克</td>\n",
       "      <td>grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>新</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>或</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21567</th>\n",
       "      <td>刷刷</td>\n",
       "      <td>brush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21568</th>\n",
       "      <td>相思病</td>\n",
       "      <td>lovesick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21569</th>\n",
       "      <td>復原力</td>\n",
       "      <td>resilience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21570</th>\n",
       "      <td>烤麵包機</td>\n",
       "      <td>toaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21571</th>\n",
       "      <td>鹼液</td>\n",
       "      <td>lye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21572</th>\n",
       "      <td>雨絲</td>\n",
       "      <td>drizzle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21573</th>\n",
       "      <td>爐子</td>\n",
       "      <td>stoves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21574</th>\n",
       "      <td>爐子</td>\n",
       "      <td>stove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21575</th>\n",
       "      <td>爐子</td>\n",
       "      <td>furnace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21576</th>\n",
       "      <td>哈欠</td>\n",
       "      <td>yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21577</th>\n",
       "      <td>結賬</td>\n",
       "      <td>checkout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21578</th>\n",
       "      <td>安息吧</td>\n",
       "      <td>rip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21579</th>\n",
       "      <td>牛排館</td>\n",
       "      <td>steakhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21580</th>\n",
       "      <td>案文</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21581</th>\n",
       "      <td>揮金如土</td>\n",
       "      <td>lavishly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21582</th>\n",
       "      <td>膿腫</td>\n",
       "      <td>abscesses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21583</th>\n",
       "      <td>郵袋</td>\n",
       "      <td>pouch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21584</th>\n",
       "      <td>留級生</td>\n",
       "      <td>repeaters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21585</th>\n",
       "      <td>草酸鹽</td>\n",
       "      <td>oxalate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21586</th>\n",
       "      <td>鍩</td>\n",
       "      <td>nobelium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21587</th>\n",
       "      <td>螺絲刀</td>\n",
       "      <td>screwdriver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21588</th>\n",
       "      <td>動因</td>\n",
       "      <td>motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21589</th>\n",
       "      <td>寄售</td>\n",
       "      <td>consignment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21590</th>\n",
       "      <td>寄售</td>\n",
       "      <td>consigned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21591</th>\n",
       "      <td>噴濺</td>\n",
       "      <td>spatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21592</th>\n",
       "      <td>牙線</td>\n",
       "      <td>floss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21593</th>\n",
       "      <td>舉目無親</td>\n",
       "      <td>unaccompanied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21594</th>\n",
       "      <td>剛玉</td>\n",
       "      <td>corundum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>氣喘病</td>\n",
       "      <td>asthma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>砂紙</td>\n",
       "      <td>sandpaper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21597 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source         target\n",
       "0          年           year\n",
       "1          月           moon\n",
       "2          月         months\n",
       "3          月          month\n",
       "4          日            day\n",
       "5          和            and\n",
       "6          村        village\n",
       "7          人            man\n",
       "8          人         people\n",
       "9          %              %\n",
       "10       小行星      asteroids\n",
       "11       小行星       asteroid\n",
       "12         大            big\n",
       "13         他             he\n",
       "14         德            tak\n",
       "15         重          heavy\n",
       "16         重        heavier\n",
       "17         一            one\n",
       "18        定向    orientation\n",
       "19        定向    directional\n",
       "20         但            but\n",
       "21         也           also\n",
       "22         拉           pull\n",
       "23         後          after\n",
       "24        留言        message\n",
       "25         市           city\n",
       "26         市   municipality\n",
       "27         克          grams\n",
       "28         新            new\n",
       "29         或             or\n",
       "...      ...            ...\n",
       "21567     刷刷          brush\n",
       "21568    相思病       lovesick\n",
       "21569    復原力     resilience\n",
       "21570   烤麵包機        toaster\n",
       "21571     鹼液            lye\n",
       "21572     雨絲        drizzle\n",
       "21573     爐子         stoves\n",
       "21574     爐子          stove\n",
       "21575     爐子        furnace\n",
       "21576     哈欠           yawn\n",
       "21577     結賬       checkout\n",
       "21578    安息吧            rip\n",
       "21579    牛排館     steakhouse\n",
       "21580     案文           text\n",
       "21581   揮金如土       lavishly\n",
       "21582     膿腫      abscesses\n",
       "21583     郵袋          pouch\n",
       "21584    留級生      repeaters\n",
       "21585    草酸鹽        oxalate\n",
       "21586      鍩       nobelium\n",
       "21587    螺絲刀    screwdriver\n",
       "21588     動因     motivation\n",
       "21589     寄售    consignment\n",
       "21590     寄售      consigned\n",
       "21591     噴濺        spatter\n",
       "21592     牙線          floss\n",
       "21593   舉目無親  unaccompanied\n",
       "21594     剛玉       corundum\n",
       "21595    氣喘病         asthma\n",
       "21596     砂紙      sandpaper\n",
       "\n",
       "[21597 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing missing vocabulary...\n",
      "Amount of missing vocab:  10349\n"
     ]
    }
   ],
   "source": [
    "print('Removing missing vocabulary...')\n",
    "\n",
    "missing = 0\n",
    "\n",
    "for n in range (len(pairs)):\n",
    "    if pairs['source'][n] not in model_source.wv.vocab or pairs['target'][n] not in model_target.wv.vocab:\n",
    "        missing = missing + 1\n",
    "        pairs = pairs.drop(n)\n",
    "\n",
    "pairs = pairs.reset_index(drop = True)\n",
    "print ('Amount of missing vocab: ', missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of pair words, excluding the missing vocabs \n",
    "# removed in previous step\n",
    "pairs['vector_source'] = [model_source[pairs['source'][n]] for n in range (len(pairs))]\n",
    "pairs['vector_target'] = [model_target[pairs['target'][n]] for n in range (len(pairs))]\n",
    "\n",
    "# first 5000 from both languages, to train translation matrix\n",
    "source_training_set = pairs['vector_source'][:10000]\n",
    "target_training_set = pairs['vector_target'][:10000]\n",
    "\n",
    "matrix_train_source = pd.DataFrame(source_training_set.tolist()).values\n",
    "matrix_train_target = pd.DataFrame(target_training_set.tolist()).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_train_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating translation matrix\n",
      "Generated translation matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Generating translation matrix')\n",
    "# Matrix W is given in  http://stackoverflow.com/questions/27980159/fit-a-linear-transformation-in-python\n",
    "translation_matrix = np.linalg.pinv(matrix_train_source).dot(matrix_train_target).T\n",
    "print ('Generated translation matrix')\n",
    "translation_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-15 17:52:07,799 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy @5 is  81 / 1000\n",
      "Accuracy @1 is  42 / 1000\n"
     ]
    }
   ],
   "source": [
    "# range to use to check accuracy\n",
    "range_start = 3000\n",
    "range_end = 4000\n",
    "\n",
    "#display_translations()\n",
    "\n",
    "# now we can check for accuracy on words 5000-6000, 1-5000 used to traning\n",
    "# translation matrix\n",
    "\n",
    "# returns matrix of true or false, true if translation is accuracy, false if not\n",
    "# accurate means the first translation (most similiar vector in target language)\n",
    "# is identical\n",
    "accuracy_at_five = [pairs['target'][n] in top_translations_list(pairs['source'][n]) for n in range(range_start, range_end)]\n",
    "print ('Accuracy @5 is ', sum(accuracy_at_five), '/', len(accuracy_at_five))\n",
    "\n",
    "accuracy_at_one = [pairs['target'][n] in top_translations_list(pairs['source'][n],1) for n in range(range_start, range_end)]\n",
    "print ('Accuracy @1 is ', sum(accuracy_at_one), '/', len(accuracy_at_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"zh_en.npy\",translation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-24 10:10:07,751 : INFO : loading Word2Vec object from model_CBOW_jp_200_wzh.w2v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-24 10:10:08,139 : INFO : loading wv recursively from model_CBOW_jp_200_wzh.w2v.wv.* with mmap=None\n",
      "2018-05-24 10:10:08,140 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-05-24 10:10:08,141 : INFO : setting ignored attribute cum_table to None\n",
      "2018-05-24 10:10:08,142 : INFO : loaded model_CBOW_jp_200_wzh.w2v\n",
      "2018-05-24 10:10:08,185 : INFO : loading Word2Vec object from model_CBOW_en_200_wzh.w2v\n",
      "2018-05-24 10:10:08,632 : INFO : loading wv recursively from model_CBOW_en_200_wzh.w2v.wv.* with mmap=None\n",
      "2018-05-24 10:10:08,634 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-05-24 10:10:08,635 : INFO : setting ignored attribute cum_table to None\n",
      "2018-05-24 10:10:08,636 : INFO : loaded model_CBOW_en_200_wzh.w2v\n"
     ]
    }
   ],
   "source": [
    "#models trained using gensim implementation of word2vec\n",
    "print('Loading models...')\n",
    "model_source = gensim.models.Word2Vec.load('model_CBOW_jp_200_wzh.w2v')\n",
    "model_target = gensim.models.Word2Vec.load('model_CBOW_en_200_wzh.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "targets = []\n",
    "with open(\"./ja-en.txt\",'r',encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        source,target = line.split()\n",
    "        sources.append(source)\n",
    "        targets.append(target)\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.DataFrame()\n",
    "pairs['source'] = pd.Series(sources)\n",
    "pairs['target'] = pd.Series(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing missing vocabulary...\n",
      "Amount of missing vocab:  20113\n"
     ]
    }
   ],
   "source": [
    "print('Removing missing vocabulary...')\n",
    "\n",
    "missing = 0\n",
    "\n",
    "for n in range (len(pairs)):\n",
    "    if pairs['source'][n] not in model_source.wv.vocab or pairs['target'][n] not in model_target.wv.vocab:\n",
    "        missing = missing + 1\n",
    "        pairs = pairs.drop(n)\n",
    "\n",
    "pairs = pairs.reset_index(drop = True)\n",
    "print ('Amount of missing vocab: ', missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of pair words, excluding the missing vocabs \n",
    "# removed in previous step\n",
    "pairs['vector_source'] = [model_source[pairs['source'][n]] for n in range (len(pairs))]\n",
    "pairs['vector_target'] = [model_target[pairs['target'][n]] for n in range (len(pairs))]\n",
    "\n",
    "# first 5000 from both languages, to train translation matrix\n",
    "source_training_set = pairs['vector_source'][:10000]\n",
    "target_training_set = pairs['vector_target'][:10000]\n",
    "\n",
    "matrix_train_source = pd.DataFrame(source_training_set.tolist()).values\n",
    "matrix_train_target = pd.DataFrame(target_training_set.tolist()).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5856, 200)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_train_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating translation matrix\n",
      "Generated translation matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Generating translation matrix')\n",
    "# Matrix W is given in  http://stackoverflow.com/questions/27980159/fit-a-linear-transformation-in-python\n",
    "translation_matrix = np.linalg.pinv(matrix_train_source).dot(matrix_train_target).T\n",
    "print ('Generated translation matrix')\n",
    "translation_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list of topn closest vectors to vectenter\n",
    "def most_similar_vector(self, vectenter, topn=5):\n",
    "    self.init_sims()\n",
    "    dists = np.dot(self.wv.syn0norm, vectenter)\n",
    "    if not topn:\n",
    "        return dists\n",
    "    best = np.argsort(dists)[::-1][:topn ]\n",
    "        # ignore (don't return) words from the input\n",
    "    result = [(self.wv.index2word[sim], float(dists[sim])) for sim in best]\n",
    "    return result[:topn]\n",
    "\n",
    "def top_translations(w,numb=5):\n",
    "    val = most_similar_vector(model_target,translation_matrix.dot(model_source[w]),numb)\n",
    "    #print 'traducwithscofres ', val\n",
    "    return val\n",
    "\n",
    "\n",
    "def top_translations_list(w, numb=5):\n",
    "    val = [top_translations(w,numb)[k][0] for k in range(numb)]\n",
    "    return val\n",
    "\n",
    "temp = 1\n",
    "#top_matches = [ pairs['target'][n] in top_translations_list(pairs['source'][n]) for n in range(5000,5003)] \n",
    "\n",
    "# print out source word and translation\n",
    "def display_translations():\n",
    "    for word_num in range(range_start, range_end):\n",
    "        source_word =  pairs['source'][word_num]\n",
    "        translations = top_translations_list(pairs['source'][word_num]) \n",
    "        print (source_word, translations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-24 10:10:34,059 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy @5 is  113 / 800\n",
      "Accuracy @1 is  68 / 800\n"
     ]
    }
   ],
   "source": [
    "# range to use to check accuracy\n",
    "range_start = 5000\n",
    "range_end = 5800\n",
    "\n",
    "#display_translations()\n",
    "\n",
    "# now we can check for accuracy on words 5000-6000, 1-5000 used to traning\n",
    "# translation matrix\n",
    "\n",
    "# returns matrix of true or false, true if translation is accuracy, false if not\n",
    "# accurate means the first translation (most similiar vector in target language)\n",
    "# is identical\n",
    "accuracy_at_five = [pairs['target'][n] in top_translations_list(pairs['source'][n]) for n in range(range_start, range_end)]\n",
    "print ('Accuracy @5 is ', sum(accuracy_at_five), '/', len(accuracy_at_five))\n",
    "\n",
    "accuracy_at_one = [pairs['target'][n] in top_translations_list(pairs['source'][n],1) for n in range(range_start, range_end)]\n",
    "print ('Accuracy @1 is ', sum(accuracy_at_one), '/', len(accuracy_at_one))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"jp_en_200.npy\",translation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-24 11:00:28,858 : INFO : loading Word2Vec object from model_CBOW_zh_200_wzh.w2v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-24 11:00:29,478 : INFO : loading wv recursively from model_CBOW_zh_200_wzh.w2v.wv.* with mmap=None\n",
      "2018-05-24 11:00:29,479 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-05-24 11:00:29,481 : INFO : setting ignored attribute cum_table to None\n",
      "2018-05-24 11:00:29,482 : INFO : loaded model_CBOW_zh_200_wzh.w2v\n",
      "2018-05-24 11:00:29,552 : INFO : loading Word2Vec object from model_CBOW_en_200_wzh.w2v\n",
      "2018-05-24 11:00:29,987 : INFO : loading wv recursively from model_CBOW_en_200_wzh.w2v.wv.* with mmap=None\n",
      "2018-05-24 11:00:29,988 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-05-24 11:00:29,989 : INFO : setting ignored attribute cum_table to None\n",
      "2018-05-24 11:00:29,990 : INFO : loaded model_CBOW_en_200_wzh.w2v\n"
     ]
    }
   ],
   "source": [
    "# models trained using gensim implementation of word2vec\n",
    "print('Loading models...')\n",
    "model_source = gensim.models.Word2Vec.load('model_CBOW_zh_200_wzh.w2v')\n",
    "model_target = gensim.models.Word2Vec.load('model_CBOW_en_200_wzh.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.DataFrame()\n",
    "pairs['source'] = pd.Series(sources)\n",
    "pairs['target'] = pd.Series(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing missing vocabulary...\n",
      "Amount of missing vocab:  24454\n"
     ]
    }
   ],
   "source": [
    "print('Removing missing vocabulary...')\n",
    "\n",
    "missing = 0\n",
    "\n",
    "for n in range (len(pairs)):\n",
    "    if pairs['source'][n] not in model_source.wv.vocab or pairs['target'][n] not in model_target.wv.vocab:\n",
    "        missing = missing + 1\n",
    "        pairs = pairs.drop(n)\n",
    "\n",
    "pairs = pairs.reset_index(drop = True)\n",
    "print ('Amount of missing vocab: ', missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of pair words, excluding the missing vocabs \n",
    "# removed in previous step\n",
    "pairs['vector_source'] = [model_source[pairs['source'][n]] for n in range (len(pairs))]\n",
    "pairs['vector_target'] = [model_target[pairs['target'][n]] for n in range (len(pairs))]\n",
    "\n",
    "# first 5000 from both languages, to train translation matrix\n",
    "source_training_set = pairs['vector_source'][:10000]\n",
    "target_training_set = pairs['vector_target'][:10000]\n",
    "\n",
    "matrix_train_source = pd.DataFrame(source_training_set.tolist()).values\n",
    "matrix_train_target = pd.DataFrame(target_training_set.tolist()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1515, 200)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_train_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating translation matrix\n",
      "Generated translation matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Generating translation matrix')\n",
    "# Matrix W is given in  http://stackoverflow.com/questions/27980159/fit-a-linear-transformation-in-python\n",
    "translation_matrix = np.linalg.pinv(matrix_train_source).dot(matrix_train_target).T\n",
    "print ('Generated translation matrix')\n",
    "translation_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list of topn closest vectors to vectenter\n",
    "def most_similar_vector(self, vectenter, topn=5):\n",
    "    self.init_sims()\n",
    "    dists = np.dot(self.wv.syn0norm, vectenter)\n",
    "    if not topn:\n",
    "        return dists\n",
    "    best = np.argsort(dists)[::-1][:topn ]\n",
    "        # ignore (don't return) words from the input\n",
    "    result = [(self.wv.index2word[sim], float(dists[sim])) for sim in best]\n",
    "    return result[:topn]\n",
    "\n",
    "def top_translations(w,numb=5):\n",
    "    val = most_similar_vector(model_target,translation_matrix.dot(model_source[w]),numb)\n",
    "    #print 'traducwithscofres ', val\n",
    "    return val\n",
    "\n",
    "\n",
    "def top_translations_list(w, numb=5):\n",
    "    val = [top_translations(w,numb)[k][0] for k in range(numb)]\n",
    "    return val\n",
    "\n",
    "temp = 1\n",
    "#top_matches = [ pairs['target'][n] in top_translations_list(pairs['source'][n]) for n in range(5000,5003)] \n",
    "\n",
    "# print out source word and translation\n",
    "def display_translations():\n",
    "    for word_num in range(range_start, range_end):\n",
    "        source_word =  pairs['source'][word_num]\n",
    "        translations = top_translations_list(pairs['source'][word_num]) \n",
    "        print (source_word, translations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy @5 is  12 / 100\n",
      "Accuracy @1 is  11 / 100\n"
     ]
    }
   ],
   "source": [
    "# range to use to check accuracy\n",
    "range_start = 1400\n",
    "range_end = 1500\n",
    "\n",
    "#display_translations()\n",
    "\n",
    "# now we can check for accuracy on words 5000-6000, 1-5000 used to traning\n",
    "# translation matrix\n",
    "\n",
    "# returns matrix of true or false, true if translation is accuracy, false if not\n",
    "# accurate means the first translation (most similiar vector in target language)\n",
    "# is identical\n",
    "accuracy_at_five = [pairs['target'][n] in top_translations_list(pairs['source'][n]) for n in range(range_start, range_end)]\n",
    "print ('Accuracy @5 is ', sum(accuracy_at_five), '/', len(accuracy_at_five))\n",
    "\n",
    "accuracy_at_one = [pairs['target'][n] in top_translations_list(pairs['source'][n],1) for n in range(range_start, range_end)]\n",
    "print ('Accuracy @1 is ', sum(accuracy_at_one), '/', len(accuracy_at_one))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"zh_en_200.npy\",translation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
