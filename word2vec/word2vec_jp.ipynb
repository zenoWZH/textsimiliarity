{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from mpltools import style\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topnum = 10\n",
    "f = open('./data/news/wo_empty_line_jp_1000.txt','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = f.readlines()\n",
    "texts = [ [word for word in document.split()] for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['米',\n",
       " '商務省',\n",
       " '発表',\n",
       " 'する',\n",
       " '建設',\n",
       " '支出',\n",
       " '以下',\n",
       " 'とおり',\n",
       " '季節調整',\n",
       " '年率',\n",
       " '総',\n",
       " '建設',\n",
       " '支出',\n",
       " '民間',\n",
       " '部門',\n",
       " '居住',\n",
       " '宿泊施設',\n",
       " 'オフィス',\n",
       " '商業',\n",
       " '輸送',\n",
       " '製造',\n",
       " '公共',\n",
       " '部門',\n",
       " '教育',\n",
       " '高速',\n",
       " '道路',\n",
       " '前回',\n",
       " '発表',\n",
       " '総',\n",
       " '建設',\n",
       " '支出',\n",
       " '民間',\n",
       " '部門',\n",
       " '公共',\n",
       " '部門',\n",
       " 'エコノミスト',\n",
       " '予想',\n",
       " 'ロイター',\n",
       " '調査']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(texts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = word2vec.LineSentence('./data/news/wo_empty_line_jp.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-10 18:00:49,094 : INFO : collecting all words and their counts\n",
      "2018-01-10 18:00:49,263 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-01-10 18:00:49,777 : INFO : PROGRESS: at sentence #10000, processed 1351313 words, keeping 19559 word types\n",
      "2018-01-10 18:00:50,197 : INFO : PROGRESS: at sentence #20000, processed 2652910 words, keeping 25997 word types\n",
      "2018-01-10 18:00:50,539 : INFO : PROGRESS: at sentence #30000, processed 3877830 words, keeping 31059 word types\n",
      "2018-01-10 18:00:50,881 : INFO : PROGRESS: at sentence #40000, processed 5128183 words, keeping 34668 word types\n",
      "2018-01-10 18:00:51,220 : INFO : PROGRESS: at sentence #50000, processed 6351900 words, keeping 37965 word types\n",
      "2018-01-10 18:00:51,538 : INFO : PROGRESS: at sentence #60000, processed 7514847 words, keeping 40269 word types\n",
      "2018-01-10 18:00:51,629 : INFO : collected 40968 word types from a corpus of 7841326 raw words and 63386 sentences\n",
      "2018-01-10 18:00:51,630 : INFO : Loading a fresh vocabulary\n",
      "2018-01-10 18:00:51,675 : INFO : min_count=5 retains 23326 unique words (56% of original 40968, drops 17642)\n",
      "2018-01-10 18:00:51,676 : INFO : min_count=5 leaves 7806294 word corpus (99% of original 7841326, drops 35032)\n",
      "2018-01-10 18:00:51,730 : INFO : deleting the raw counts dictionary of 40968 items\n",
      "2018-01-10 18:00:51,732 : INFO : sample=0.001 downsamples 29 most-common words\n",
      "2018-01-10 18:00:51,733 : INFO : downsampling leaves estimated 6848023 word corpus (87.7% of prior 7806294)\n",
      "2018-01-10 18:00:51,734 : INFO : estimated required memory for 23326 words and 100 dimensions: 30323800 bytes\n",
      "2018-01-10 18:00:51,779 : INFO : resetting layer weights\n",
      "2018-01-10 18:00:52,041 : INFO : training model with 14 workers on 23326 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-01-10 18:00:53,056 : INFO : PROGRESS: at 2.01% examples, 767370 words/s, in_qsize 24, out_qsize 3\n",
      "2018-01-10 18:00:54,058 : INFO : PROGRESS: at 5.34% examples, 997225 words/s, in_qsize 28, out_qsize 0\n",
      "2018-01-10 18:00:55,069 : INFO : PROGRESS: at 9.06% examples, 1076926 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:00:56,079 : INFO : PROGRESS: at 12.32% examples, 1088745 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:00:57,081 : INFO : PROGRESS: at 15.53% examples, 1087869 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:00:58,092 : INFO : PROGRESS: at 19.46% examples, 1108026 words/s, in_qsize 28, out_qsize 0\n",
      "2018-01-10 18:00:59,093 : INFO : PROGRESS: at 22.62% examples, 1110766 words/s, in_qsize 28, out_qsize 1\n",
      "2018-01-10 18:01:00,116 : INFO : PROGRESS: at 25.94% examples, 1121723 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:01,118 : INFO : PROGRESS: at 29.20% examples, 1119233 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:02,127 : INFO : PROGRESS: at 32.66% examples, 1124953 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:03,133 : INFO : PROGRESS: at 36.37% examples, 1132543 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:04,141 : INFO : PROGRESS: at 40.12% examples, 1135494 words/s, in_qsize 27, out_qsize 2\n",
      "2018-01-10 18:01:05,150 : INFO : PROGRESS: at 43.20% examples, 1136028 words/s, in_qsize 28, out_qsize 0\n",
      "2018-01-10 18:01:06,151 : INFO : PROGRESS: at 46.45% examples, 1137843 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:07,157 : INFO : PROGRESS: at 49.87% examples, 1141291 words/s, in_qsize 26, out_qsize 1\n",
      "2018-01-10 18:01:08,162 : INFO : PROGRESS: at 53.55% examples, 1146930 words/s, in_qsize 26, out_qsize 2\n",
      "2018-01-10 18:01:09,173 : INFO : PROGRESS: at 57.22% examples, 1150361 words/s, in_qsize 26, out_qsize 2\n",
      "2018-01-10 18:01:10,179 : INFO : PROGRESS: at 60.85% examples, 1151816 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:11,194 : INFO : PROGRESS: at 64.01% examples, 1151599 words/s, in_qsize 23, out_qsize 1\n",
      "2018-01-10 18:01:12,198 : INFO : PROGRESS: at 67.40% examples, 1151974 words/s, in_qsize 28, out_qsize 0\n",
      "2018-01-10 18:01:13,201 : INFO : PROGRESS: at 70.90% examples, 1155257 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:14,206 : INFO : PROGRESS: at 74.82% examples, 1160623 words/s, in_qsize 26, out_qsize 1\n",
      "2018-01-10 18:01:15,207 : INFO : PROGRESS: at 78.24% examples, 1158951 words/s, in_qsize 28, out_qsize 0\n",
      "2018-01-10 18:01:16,210 : INFO : PROGRESS: at 81.65% examples, 1158767 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:17,211 : INFO : PROGRESS: at 84.89% examples, 1160107 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:18,219 : INFO : PROGRESS: at 88.32% examples, 1160297 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:19,221 : INFO : PROGRESS: at 91.66% examples, 1159402 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:20,223 : INFO : PROGRESS: at 94.95% examples, 1158926 words/s, in_qsize 26, out_qsize 1\n",
      "2018-01-10 18:01:21,240 : INFO : PROGRESS: at 98.59% examples, 1157997 words/s, in_qsize 28, out_qsize 0\n",
      "2018-01-10 18:01:21,493 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2018-01-10 18:01:21,499 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2018-01-10 18:01:21,503 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2018-01-10 18:01:21,506 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2018-01-10 18:01:21,513 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-01-10 18:01:21,516 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-01-10 18:01:21,517 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-01-10 18:01:21,518 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-01-10 18:01:21,529 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-01-10 18:01:21,531 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-01-10 18:01:21,536 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-01-10 18:01:21,542 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-01-10 18:01:21,547 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-01-10 18:01:21,551 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-01-10 18:01:21,552 : INFO : training on 39206630 raw words (34241649 effective words) took 29.5s, 1160569 effective words/s\n",
      "2018-01-10 18:01:21,552 : INFO : saving Word2Vec object under modeljp_sg.w2v, separately None\n",
      "2018-01-10 18:01:21,553 : INFO : not storing attribute syn0norm\n",
      "2018-01-10 18:01:21,554 : INFO : not storing attribute cum_table\n",
      "2018-01-10 18:01:22,052 : INFO : saved modeljp_sg.w2v\n",
      "2018-01-10 18:01:22,053 : INFO : collecting all words and their counts\n",
      "2018-01-10 18:01:22,053 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-01-10 18:01:22,428 : INFO : PROGRESS: at sentence #10000, processed 1351313 words, keeping 19559 word types\n",
      "2018-01-10 18:01:22,797 : INFO : PROGRESS: at sentence #20000, processed 2652910 words, keeping 25997 word types\n",
      "2018-01-10 18:01:23,133 : INFO : PROGRESS: at sentence #30000, processed 3877830 words, keeping 31059 word types\n",
      "2018-01-10 18:01:23,485 : INFO : PROGRESS: at sentence #40000, processed 5128183 words, keeping 34668 word types\n",
      "2018-01-10 18:01:23,841 : INFO : PROGRESS: at sentence #50000, processed 6351900 words, keeping 37965 word types\n",
      "2018-01-10 18:01:24,168 : INFO : PROGRESS: at sentence #60000, processed 7514847 words, keeping 40269 word types\n",
      "2018-01-10 18:01:24,265 : INFO : collected 40968 word types from a corpus of 7841326 raw words and 63386 sentences\n",
      "2018-01-10 18:01:24,266 : INFO : Loading a fresh vocabulary\n",
      "2018-01-10 18:01:24,306 : INFO : min_count=5 retains 23326 unique words (56% of original 40968, drops 17642)\n",
      "2018-01-10 18:01:24,307 : INFO : min_count=5 leaves 7806294 word corpus (99% of original 7841326, drops 35032)\n",
      "2018-01-10 18:01:24,361 : INFO : deleting the raw counts dictionary of 40968 items\n",
      "2018-01-10 18:01:24,362 : INFO : sample=0.001 downsamples 29 most-common words\n",
      "2018-01-10 18:01:24,363 : INFO : downsampling leaves estimated 6848023 word corpus (87.7% of prior 7806294)\n",
      "2018-01-10 18:01:24,364 : INFO : estimated required memory for 23326 words and 100 dimensions: 30323800 bytes\n",
      "2018-01-10 18:01:24,409 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-10 18:01:24,643 : INFO : training model with 14 workers on 23326 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-01-10 18:01:25,661 : INFO : PROGRESS: at 1.92% examples, 713127 words/s, in_qsize 27, out_qsize 1\n",
      "2018-01-10 18:01:26,665 : INFO : PROGRESS: at 3.97% examples, 738087 words/s, in_qsize 23, out_qsize 5\n",
      "2018-01-10 18:01:27,683 : INFO : PROGRESS: at 6.39% examples, 768844 words/s, in_qsize 25, out_qsize 2\n",
      "2018-01-10 18:01:28,685 : INFO : PROGRESS: at 8.69% examples, 777838 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:29,687 : INFO : PROGRESS: at 10.93% examples, 774738 words/s, in_qsize 28, out_qsize 0\n",
      "2018-01-10 18:01:30,701 : INFO : PROGRESS: at 13.29% examples, 772212 words/s, in_qsize 26, out_qsize 4\n",
      "2018-01-10 18:01:31,709 : INFO : PROGRESS: at 15.52% examples, 774140 words/s, in_qsize 26, out_qsize 1\n",
      "2018-01-10 18:01:32,735 : INFO : PROGRESS: at 17.97% examples, 770215 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:33,743 : INFO : PROGRESS: at 20.40% examples, 771456 words/s, in_qsize 26, out_qsize 1\n",
      "2018-01-10 18:01:34,759 : INFO : PROGRESS: at 22.48% examples, 769708 words/s, in_qsize 26, out_qsize 1\n",
      "2018-01-10 18:01:35,782 : INFO : PROGRESS: at 24.45% examples, 764850 words/s, in_qsize 26, out_qsize 1\n",
      "2018-01-10 18:01:36,785 : INFO : PROGRESS: at 26.67% examples, 763542 words/s, in_qsize 28, out_qsize 0\n",
      "2018-01-10 18:01:37,823 : INFO : PROGRESS: at 28.83% examples, 761333 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:38,828 : INFO : PROGRESS: at 31.12% examples, 761824 words/s, in_qsize 28, out_qsize 1\n",
      "2018-01-10 18:01:39,833 : INFO : PROGRESS: at 33.41% examples, 762142 words/s, in_qsize 26, out_qsize 1\n",
      "2018-01-10 18:01:40,855 : INFO : PROGRESS: at 35.43% examples, 758194 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:41,870 : INFO : PROGRESS: at 37.90% examples, 758220 words/s, in_qsize 26, out_qsize 1\n",
      "2018-01-10 18:01:42,911 : INFO : PROGRESS: at 40.42% examples, 759915 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:43,922 : INFO : PROGRESS: at 42.69% examples, 762562 words/s, in_qsize 23, out_qsize 4\n",
      "2018-01-10 18:01:44,937 : INFO : PROGRESS: at 44.72% examples, 761217 words/s, in_qsize 28, out_qsize 0\n",
      "2018-01-10 18:01:45,975 : INFO : PROGRESS: at 46.85% examples, 758892 words/s, in_qsize 27, out_qsize 4\n",
      "2018-01-10 18:01:47,004 : INFO : PROGRESS: at 49.16% examples, 759726 words/s, in_qsize 25, out_qsize 2\n",
      "2018-01-10 18:01:48,030 : INFO : PROGRESS: at 51.53% examples, 760138 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:49,031 : INFO : PROGRESS: at 53.76% examples, 760556 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:50,044 : INFO : PROGRESS: at 55.92% examples, 759329 words/s, in_qsize 25, out_qsize 2\n",
      "2018-01-10 18:01:51,048 : INFO : PROGRESS: at 58.29% examples, 757693 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:52,073 : INFO : PROGRESS: at 60.55% examples, 758079 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:53,074 : INFO : PROGRESS: at 62.68% examples, 757774 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:54,100 : INFO : PROGRESS: at 64.83% examples, 758012 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:55,123 : INFO : PROGRESS: at 66.98% examples, 757159 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:56,124 : INFO : PROGRESS: at 69.14% examples, 757078 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:57,129 : INFO : PROGRESS: at 71.41% examples, 756894 words/s, in_qsize 28, out_qsize 1\n",
      "2018-01-10 18:01:58,141 : INFO : PROGRESS: at 73.55% examples, 756284 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:01:59,144 : INFO : PROGRESS: at 75.71% examples, 755706 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:00,146 : INFO : PROGRESS: at 78.18% examples, 755624 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:01,150 : INFO : PROGRESS: at 80.50% examples, 756590 words/s, in_qsize 28, out_qsize 0\n",
      "2018-01-10 18:02:02,154 : INFO : PROGRESS: at 82.56% examples, 755878 words/s, in_qsize 25, out_qsize 2\n",
      "2018-01-10 18:02:03,172 : INFO : PROGRESS: at 84.67% examples, 755969 words/s, in_qsize 27, out_qsize 3\n",
      "2018-01-10 18:02:04,185 : INFO : PROGRESS: at 86.88% examples, 755980 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:05,212 : INFO : PROGRESS: at 88.98% examples, 754851 words/s, in_qsize 26, out_qsize 1\n",
      "2018-01-10 18:02:06,221 : INFO : PROGRESS: at 91.15% examples, 754265 words/s, in_qsize 25, out_qsize 2\n",
      "2018-01-10 18:02:07,269 : INFO : PROGRESS: at 93.40% examples, 753379 words/s, in_qsize 25, out_qsize 2\n",
      "2018-01-10 18:02:08,289 : INFO : PROGRESS: at 95.53% examples, 752933 words/s, in_qsize 27, out_qsize 4\n",
      "2018-01-10 18:02:09,290 : INFO : PROGRESS: at 97.99% examples, 753147 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:09,876 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2018-01-10 18:02:09,892 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2018-01-10 18:02:09,914 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2018-01-10 18:02:09,918 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2018-01-10 18:02:09,929 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-01-10 18:02:09,938 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-01-10 18:02:09,941 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-01-10 18:02:09,942 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-01-10 18:02:09,945 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-01-10 18:02:09,951 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-01-10 18:02:09,953 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-01-10 18:02:09,955 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-01-10 18:02:09,957 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-01-10 18:02:09,970 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-01-10 18:02:09,972 : INFO : training on 39206630 raw words (34240602 effective words) took 45.3s, 755459 effective words/s\n",
      "2018-01-10 18:02:09,973 : INFO : saving Word2Vec object under modeljp_CBOW.w2v, separately None\n",
      "2018-01-10 18:02:09,974 : INFO : not storing attribute syn0norm\n",
      "2018-01-10 18:02:09,975 : INFO : not storing attribute cum_table\n",
      "2018-01-10 18:02:10,496 : INFO : saved modeljp_CBOW.w2v\n"
     ]
    }
   ],
   "source": [
    "model_sg = word2vec.Word2Vec(sentences,workers=14,size=100,sg=1,alpha=0.001)\n",
    "model_sg.save('modeljp_sg.w2v')\n",
    "model_CBOW = word2vec.Word2Vec(sentences,workers=14,size=100,sg=0,alpha=0.001)\n",
    "model_CBOW.save('modeljp_CBOW.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-10 18:06:02,789 : INFO : loading Word2Vec object from modeljp_sg.w2v\n",
      "2018-01-10 18:06:03,057 : INFO : loading wv recursively from modeljp_sg.w2v.wv.* with mmap=None\n",
      "2018-01-10 18:06:03,058 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-01-10 18:06:03,060 : INFO : setting ignored attribute cum_table to None\n",
      "2018-01-10 18:06:03,061 : INFO : loaded modeljp_sg.w2v\n",
      "2018-01-10 18:06:03,106 : INFO : loading Word2Vec object from modeljp_CBOW.w2v\n",
      "2018-01-10 18:06:03,251 : INFO : loading wv recursively from modeljp_CBOW.w2v.wv.* with mmap=None\n",
      "2018-01-10 18:06:03,252 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-01-10 18:06:03,253 : INFO : setting ignored attribute cum_table to None\n",
      "2018-01-10 18:06:03,255 : INFO : loaded modeljp_CBOW.w2v\n"
     ]
    }
   ],
   "source": [
    "model_sg = word2vec.Word2Vec.load('modeljp_sg.w2v')\n",
    "model_CBOW = word2vec.Word2Vec.load('modeljp_CBOW.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-10 18:02:11,717 : INFO : collecting all words and their counts\n",
      "2018-01-10 18:02:11,718 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-01-10 18:02:12,113 : INFO : PROGRESS: at sentence #10000, processed 1351313 words, keeping 19559 word types\n",
      "2018-01-10 18:02:12,476 : INFO : PROGRESS: at sentence #20000, processed 2652910 words, keeping 25997 word types\n",
      "2018-01-10 18:02:12,813 : INFO : PROGRESS: at sentence #30000, processed 3877830 words, keeping 31059 word types\n",
      "2018-01-10 18:02:13,157 : INFO : PROGRESS: at sentence #40000, processed 5128183 words, keeping 34668 word types\n",
      "2018-01-10 18:02:13,501 : INFO : PROGRESS: at sentence #50000, processed 6351900 words, keeping 37965 word types\n",
      "2018-01-10 18:02:13,827 : INFO : PROGRESS: at sentence #60000, processed 7514847 words, keeping 40269 word types\n",
      "2018-01-10 18:02:13,923 : INFO : collected 40968 word types from a corpus of 7841326 raw words and 63386 sentences\n",
      "2018-01-10 18:02:13,924 : INFO : Loading a fresh vocabulary\n",
      "2018-01-10 18:02:14,031 : INFO : min_count=0 retains 40968 unique words (100% of original 40968, drops 0)\n",
      "2018-01-10 18:02:14,032 : INFO : min_count=0 leaves 7841326 word corpus (100% of original 7841326, drops 0)\n",
      "2018-01-10 18:02:14,132 : INFO : deleting the raw counts dictionary of 40968 items\n",
      "2018-01-10 18:02:14,133 : INFO : sample=0.001 downsamples 29 most-common words\n",
      "2018-01-10 18:02:14,134 : INFO : downsampling leaves estimated 6885282 word corpus (87.8% of prior 7841326)\n",
      "2018-01-10 18:02:14,135 : INFO : estimated required memory for 40968 words and 64 dimensions: 41459616 bytes\n",
      "2018-01-10 18:02:14,216 : INFO : resetting layer weights\n",
      "2018-01-10 18:02:14,610 : INFO : training model with 14 workers on 40968 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=63 window=5\n",
      "2018-01-10 18:02:15,795 : INFO : PROGRESS: at 0.33% examples, 109799 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:17,044 : INFO : PROGRESS: at 0.93% examples, 152887 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:18,046 : INFO : PROGRESS: at 1.64% examples, 176651 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:19,046 : INFO : PROGRESS: at 2.18% examples, 191024 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:20,060 : INFO : PROGRESS: at 2.71% examples, 185785 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:21,177 : INFO : PROGRESS: at 3.32% examples, 188435 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:22,252 : INFO : PROGRESS: at 3.97% examples, 195924 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:23,316 : INFO : PROGRESS: at 4.58% examples, 196877 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:24,317 : INFO : PROGRESS: at 5.17% examples, 198825 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:25,353 : INFO : PROGRESS: at 5.72% examples, 198936 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:26,355 : INFO : PROGRESS: at 6.39% examples, 199756 words/s, in_qsize 28, out_qsize 0\n",
      "2018-01-10 18:02:27,356 : INFO : PROGRESS: at 6.95% examples, 198944 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:28,427 : INFO : PROGRESS: at 7.64% examples, 199922 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:29,487 : INFO : PROGRESS: at 8.32% examples, 200999 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:30,545 : INFO : PROGRESS: at 8.87% examples, 201462 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:31,549 : INFO : PROGRESS: at 9.53% examples, 201864 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:32,587 : INFO : PROGRESS: at 10.03% examples, 203372 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:33,668 : INFO : PROGRESS: at 10.75% examples, 203257 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:34,728 : INFO : PROGRESS: at 11.47% examples, 202934 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:35,733 : INFO : PROGRESS: at 12.06% examples, 205188 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:36,744 : INFO : PROGRESS: at 12.73% examples, 204878 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:37,795 : INFO : PROGRESS: at 13.31% examples, 203115 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:38,808 : INFO : PROGRESS: at 13.97% examples, 203993 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:39,866 : INFO : PROGRESS: at 14.69% examples, 204387 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:40,866 : INFO : PROGRESS: at 15.18% examples, 205099 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:41,938 : INFO : PROGRESS: at 15.86% examples, 204980 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:42,985 : INFO : PROGRESS: at 16.61% examples, 204462 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:43,995 : INFO : PROGRESS: at 17.17% examples, 205198 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:45,011 : INFO : PROGRESS: at 17.87% examples, 205186 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:46,029 : INFO : PROGRESS: at 18.62% examples, 205751 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:47,035 : INFO : PROGRESS: at 19.08% examples, 204741 words/s, in_qsize 28, out_qsize 0\n",
      "2018-01-10 18:02:48,035 : INFO : PROGRESS: at 19.85% examples, 204854 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:49,057 : INFO : PROGRESS: at 20.45% examples, 205794 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:50,073 : INFO : PROGRESS: at 21.01% examples, 205284 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:51,091 : INFO : PROGRESS: at 21.63% examples, 205292 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:52,189 : INFO : PROGRESS: at 22.14% examples, 205231 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:53,213 : INFO : PROGRESS: at 22.83% examples, 205645 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:54,308 : INFO : PROGRESS: at 23.45% examples, 205868 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:55,391 : INFO : PROGRESS: at 24.05% examples, 206348 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:56,397 : INFO : PROGRESS: at 24.60% examples, 205928 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:57,489 : INFO : PROGRESS: at 25.21% examples, 206135 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:58,509 : INFO : PROGRESS: at 25.84% examples, 206480 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:02:59,536 : INFO : PROGRESS: at 26.52% examples, 206217 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:00,576 : INFO : PROGRESS: at 27.10% examples, 206066 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:01,606 : INFO : PROGRESS: at 27.77% examples, 206185 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:02,626 : INFO : PROGRESS: at 28.36% examples, 206186 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:03,648 : INFO : PROGRESS: at 28.95% examples, 206360 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:04,731 : INFO : PROGRESS: at 29.67% examples, 206428 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:05,745 : INFO : PROGRESS: at 30.17% examples, 207125 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:06,806 : INFO : PROGRESS: at 30.77% examples, 206249 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:07,912 : INFO : PROGRESS: at 31.59% examples, 206379 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:08,947 : INFO : PROGRESS: at 32.14% examples, 206919 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:09,970 : INFO : PROGRESS: at 32.82% examples, 206720 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:11,094 : INFO : PROGRESS: at 33.44% examples, 206318 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:12,099 : INFO : PROGRESS: at 34.20% examples, 206797 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:13,200 : INFO : PROGRESS: at 34.88% examples, 207040 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:14,397 : INFO : PROGRESS: at 35.49% examples, 206937 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:15,412 : INFO : PROGRESS: at 36.18% examples, 206751 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:16,536 : INFO : PROGRESS: at 36.97% examples, 206683 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:17,559 : INFO : PROGRESS: at 37.64% examples, 207075 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:18,734 : INFO : PROGRESS: at 38.41% examples, 206791 words/s, in_qsize 28, out_qsize 0\n",
      "2018-01-10 18:03:19,893 : INFO : PROGRESS: at 39.00% examples, 206838 words/s, in_qsize 27, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-10 18:03:20,979 : INFO : PROGRESS: at 39.87% examples, 206987 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:21,980 : INFO : PROGRESS: at 40.40% examples, 206988 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:23,020 : INFO : PROGRESS: at 40.91% examples, 206635 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:24,236 : INFO : PROGRESS: at 41.64% examples, 206528 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:25,248 : INFO : PROGRESS: at 42.22% examples, 207101 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:26,300 : INFO : PROGRESS: at 42.90% examples, 207083 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:27,308 : INFO : PROGRESS: at 43.39% examples, 206812 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:28,354 : INFO : PROGRESS: at 43.97% examples, 207043 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:29,359 : INFO : PROGRESS: at 44.55% examples, 207026 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:30,370 : INFO : PROGRESS: at 45.17% examples, 207229 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:31,379 : INFO : PROGRESS: at 45.72% examples, 207204 words/s, in_qsize 27, out_qsize 0\n",
      "2018-01-10 18:03:32,415 : INFO : PROGRESS: at 46.30% examples, 206800 words/s, in_qsize 27, out_qsize 0\n"
     ]
    }
   ],
   "source": [
    "model_sg_2 = word2vec.Word2Vec(sentences,workers=14,size=64,sg=1,negative=63,max_vocab_size=None,min_count=0)\n",
    "model_sg_2.save('modeljp_sg_2.w2v')\n",
    "\n",
    "model_CBOW_2 = word2vec.Word2Vec(sentences,workers=14,size=64,sg=0,negative=63,max_vocab_size=None,min_count=0)\n",
    "model_CBOW_2.save('modeljp_CBOW_2.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-10 18:06:05,484 : INFO : loading Word2Vec object from modeljp_sg_2.w2v\n",
      "2018-01-10 18:06:05,792 : INFO : loading wv recursively from modeljp_sg_2.w2v.wv.* with mmap=None\n",
      "2018-01-10 18:06:05,793 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-01-10 18:06:05,795 : INFO : setting ignored attribute cum_table to None\n",
      "2018-01-10 18:06:05,796 : INFO : loaded modeljp_sg_2.w2v\n",
      "2018-01-10 18:06:05,870 : INFO : loading Word2Vec object from modeljp_CBOW_2.w2v\n",
      "2018-01-10 18:06:06,069 : INFO : loading wv recursively from modeljp_CBOW_2.w2v.wv.* with mmap=None\n",
      "2018-01-10 18:06:06,070 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-01-10 18:06:06,072 : INFO : setting ignored attribute cum_table to None\n",
      "2018-01-10 18:06:06,074 : INFO : loaded modeljp_CBOW_2.w2v\n"
     ]
    }
   ],
   "source": [
    "model_sg_2 = word2vec.Word2Vec.load('modeljp_sg_2.w2v')\n",
    "model_CBOW_2 = word2vec.Word2Vec.load('modeljp_CBOW_2.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-10 19:32:35,738 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ロイター', 0.8708531856536865),\n",
       " ('データ', 0.7952598333358765),\n",
       " ('エコノミスト', 0.7944284677505493),\n",
       " ('集計', 0.7871703505516052),\n",
       " ('調査対象', 0.7859119176864624),\n",
       " ('算出', 0.7818284034729004),\n",
       " ('リポート', 0.7786976099014282),\n",
       " ('事前', 0.7734562158584595),\n",
       " ('据え置き', 0.7697207927703857),\n",
       " ('報告', 0.7640864849090576)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.most_similar('調査',topn=topnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('公共投資', 0.9853838086128235),\n",
       " ('財政支出', 0.9830482006072998),\n",
       " ('政府支出', 0.9819355607032776),\n",
       " ('税金', 0.981545090675354),\n",
       " ('世帯', 0.9813950061798096),\n",
       " ('先行指標', 0.9811976552009583),\n",
       " ('新規雇用', 0.9810927510261536),\n",
       " ('社会保障', 0.9809276461601257),\n",
       " ('給与', 0.980919599533081),\n",
       " ('連邦政府', 0.9809174537658691)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.most_similar('公共',topn=topnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('創出', 0.9479783773422241),\n",
       " ('労働市場', 0.9203675389289856),\n",
       " ('労働', 0.9130797386169434),\n",
       " ('所得', 0.9101271033287048),\n",
       " ('支出', 0.9066452383995056),\n",
       " ('生産性', 0.8958334922790527),\n",
       " ('失業率', 0.8939441442489624),\n",
       " ('緩慢', 0.8901565670967102),\n",
       " ('鈍る', 0.8864469528198242),\n",
       " ('消費者', 0.8812360763549805)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.most_similar('雇用',topn=topnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
